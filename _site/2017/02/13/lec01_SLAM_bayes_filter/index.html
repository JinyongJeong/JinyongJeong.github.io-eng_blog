<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no"><title>[SLAM] Bayes filter(베이즈 필터) &middot; Jinyong Jeong</title><meta name="description" content="SLAM framework에서 Bayes filter에 대한 설명. "> <!--[if gt IE 8]><!----><style> article,aside,dialog,figcaption,figure,footer,header,hgroup,main,nav,section{display:block}mark{background:#FF0;color:#000}template{display:none}*{-webkit-box-sizing:border-box;-moz-box-sizing:border-box;box-sizing:border-box}html,body{margin:0;padding:0}html{line-height:1.65}body{color:#515151;background-color:#fff}a{text-decoration:none}img{display:block;max-width:100%;margin:0 0 1rem}img.lead{max-width:calc(100% + 2rem);width:calc(100% + 2rem);margin-left:calc(-1rem);margin-right:calc(-1rem)}h1,h2,h3,h4,h5,h6{margin-bottom:.5rem;font-weight:600;line-height:1.25;color:#313131;text-rendering:optimizeLegibility}h1{font-size:2rem}h2{margin-top:1rem;font-size:1.5rem}p{margin-top:0;margin-bottom:1rem}p.lead{font-size:1.25rem;font-weight:300}ul,ol,dl{margin-top:0;margin-bottom:1rem}hr{position:relative;margin:1.5rem 0;border:0;border-top:1px solid #eee;border-bottom:1px solid #fff}.container{max-width:38rem;padding-left:1rem;padding-right:1rem;margin-left:auto;margin-right:auto}.page-title,.post-title{color:#303030}.page-title,.post-title{margin-top:0}.post-date{display:block;margin-top:-.25rem;margin-bottom:1rem;color:#9a9a9a;font-weight:bold}.related{padding-top:2rem;padding-bottom:2rem}.related-posts{padding-left:0;list-style:none}.related-posts>li{margin-top:1rem}.related-posts>li>*{font-weight:normal}.message{margin-bottom:1rem;padding:1rem;color:#717171;background-color:#f9f9f9;margin-left:-1rem;margin-right:-1rem}body{padding-left:0.5rem}@media (min-width: 48em){html{font-size:16px}body{padding-left:0}}@media (min-width: 58em){html{font-size:18px}}.sr-only{display:none}.backdrop{display:none}.sidebar{position:relative;z-index:4;padding:2rem 1rem;color:rgba(255,255,255,0.75);background-color:#202020;text-align:left;background-size:cover;background-position:center center;min-height:640px;min-height:100vh;margin-left:-0.5rem}.sidebar a{color:#fff}.sidebar ul{list-style:none;padding-left:0}.sidebar-sticky{position:absolute;right:1rem;bottom:1rem;left:1rem}.sidebar-about>h1{color:#fff;font-size:2rem}.sidebar-nav-item{font-weight:bold;display:block;line-height:1.75;padding:.25rem .1rem;border-top:1px solid rgba(255,255,255,0.23)}.sidebar-social>ul{min-height:3.5rem}.sidebar::before{content:"";position:absolute;top:0;left:0;bottom:0;right:0;background:rgba(32,32,32,0.33);background:-moz-linear-gradient(bottom, rgba(32,32,32,0) 0%, rgba(32,32,32,0.5) 100%);background:-webkit-linear-gradient(bottom, rgba(32,32,32,0) 0%, rgba(32,32,32,0.5) 100%);background:linear-gradient(to bottom, rgba(32,32,32,0) 0%, rgba(32,32,32,0.5) 100%)}@media (min-width: 48em){.sidebar{position:fixed;top:0;left:0;bottom:0;width:18rem;margin-left:0}}.menu{display:block;padding:1.25rem 1.5rem;color:#9a9a9a;border-bottom:none;position:fixed;top:0;left:0;z-index:2}@media (min-width: 48em){.menu{position:absolute;left:-9999px}}@media (min-width: 48em){.menu:focus{left:19.5rem}}@media (min-width: 64em){.menu:focus{left:21.5rem}}.content{padding-top:4rem;padding-bottom:4rem}@media (min-width: 48em){.content{max-width:38rem;margin-left:20rem;margin-right:2rem;border-left:none}}@media (min-width: 64em){.content{margin-left:22rem;margin-right:4rem}}.me{float:right;width:6.5rem;margin-top:-4.8rem;margin-left:1rem;border-radius:100%;position:relative}@media (min-width: 38em){.me{width:7rem;margin-top:-5.05rem}}@media (min-width: 48em){.me{width:6.5rem;margin-top:-4.8rem}}@media (min-width: 58em){.me{width:7rem;margin-top:-5.05rem}}</style><noscript><link rel="stylesheet" href="http://JinyongJeong.github.io/public/css/non-essentials.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Slab:700|PT+Serif:400,400italic,700,700italic"><link rel="stylesheet" href="http://JinyongJeong.github.io/public/css/icons.css"> </noscript><link rel="preload" href="http://JinyongJeong.github.io/public/css/non-essentials.css" as="style" onload="this.rel='stylesheet'"><style> html { font-family: "PT Serif", Georgia, serif; } :focus { outline-color: #949667; } .font-accent { font-family: "Roboto Slab", "PT Serif", Georgia, serif; } .content a, .related-posts li a:hover { color: #949667; } ::selection { color: #fff; background: #949667; } ::-moz-selection { color: #fff; background: #949667; } .sidebar { background-image: url('/public/img/2.jpg'); }</style><!--<![endif]--><link rel="canonical" href="http://localhost:4000http://JinyongJeong.github.io/2017/02/13/lec01_SLAM_bayes_filter/" /><link rel="alternate" type="application/atom+xml" title="Jinyong Jeong Atom Feed" href="http://JinyongJeong.github.io/atom.xml"> <script>!function(n,e){function t(n,e){n.onload=function(){this.onerror=this.onload=null,e(null,n)},n.onerror=function(){this.onerror=this.onload=null,e(new Error("Failed to load "+this.src),n)}}function o(n,e){n.onreadystatechange=function(){"complete"!=this.readyState&&"loaded"!=this.readyState||(this.onreadystatechange=null,e(null,n))}}n.isReady=!1,n.loadJSDeferred=function(a,r){function d(){n.isReady=!0;var d=e.createElement("script");d.src=a,r&&(("onload"in d?t:o)(d,r),d.onload||t(d,r));var i=e.getElementsByTagName("script")[0];i.parentNode.insertBefore(d,i)}n.isReady?d():n.addEventListener?n.addEventListener("load",d,!1):n.attachEvent?n.attachEvent("onload",d):n.onload=d}}(window,document); </script> <!--[if lt IE 9]> <script src="https://unpkg.com/html5shiv/dist/html5shiv.min.js"></script> <![endif]--><body> <span class="sr-only">Jump to:</span> <a id="_menu" class="menu" href="#_asidebar"> <span>☰</span> <span class="sr-only">Menu</span> </a><main class="content container" role="main"><article id="post-2017/02/13/lec01_SLAM_bayes_filter" class="post" role="article"><h1 class="post-title"> [SLAM] Bayes filter(베이즈 필터)</h1><div class="post-date"> <time datetime="2017-02-13T00:00:00+09:00">02/13/17</time> <span>on <a href="http://JinyongJeong.github.io/tag/SLAM/">SLAM</a></span></div><p class="message">SLAM framework에서 Bayes filter에 대한 설명.<hr/><p><strong>본 글은 University Freiburg의 <a href="http://ais.informatik.uni-freiburg.de/teaching/ws13/mapping/">Robot Mapping</a> 강의를 바탕으로 이해하기 쉽도록 정리하려는 목적으로 작성되었습니다. 개인적인 의견을 포함하여 작성되기 때문에 틀린 내용이 있을 수도 있습니다. 틀린 부분은 지적해주시면 확인 후 수정하겠습니다.</strong><h2 id="slamsimultaneous-localization-and-mapping">SLAM(Simultaneous Localization and Mapping)</h2><p>SLAM은 simultaneous localization and mapping의 줄임말로 위치추정(localization)과 지도생성(mapping)을 동시에 하는 연구분야를 의미한다. 이는 닭이 먼저냐 달걀이 먼저냐의 문제와 비슷하다. 자기의 위치를 추정하기 위해서는 주변환경에 대한 정보가 필요하다. 반면에 로봇이 얻을 수 있는 데이터를 이용해서 지도를 만들기 위해서는 로봇이 자신의 위치가 어디에 있는지를 정확히 알아야 한다. 따라서 위치를 알 수 없으면 지도를 만들 수 없고, 반대로 지도가 없으면 위치를 알 수 없다. 이러한 문제를 풀기 위해서 지도의 생성과 위치 추정을 동시에 수행하는 것이 SLAM이다.<h3 id="state-estimation">State estimation</h3><p>State estimation은 로봇에 주어지는 입력과, 로봇의 센서로부터 얻어지는 데이터로부터 현재의 로봇의 위치인 state와 주변환경에 대한 지도를 추정 방법이다.<pre class="MathJax_Preview"><code>p(\mathbf{x}\mid \mathbf{z}, \mathbf{u})</code></pre><script type="math/tex; mode=display">p(\mathbf{x}\mid \mathbf{z}, \mathbf{u})</script><p>위의 식은 기본적인 state estimation을 의미한다. <code class="MathJax_Preview">\mathbf{x}</code><script type="math/tex">\mathbf{x}</script> 는 로봇의 위치 및 지도(주변의 land mark들의 위치)를 의미하는 vector이며, <code class="MathJax_Preview">\mathbf{z}</code><script type="math/tex">\mathbf{z}</script> 는 로봇의 센서로부터 얻어지는 데이터로 observation이라고 부르며, <code class="MathJax_Preview">\mathbf{u}</code><script type="math/tex">\mathbf{u}</script> 는 센서의 움직임을 제어하는 입력으로 control input이라고 부른다. state estimation은 이러한 control input과 observation의 데이터를 통해 현재의 위치와 지도를 추정한다.<h3 id="bayes-theorem">bayes theorem</h3><p>베이즈 정리는 확률론과 통계학에서 두 확률변수의 사전확률(prior)과 사후확률(posterior) 사이의 관계를 나타내는 정리이다.<pre class="MathJax_Preview"><code>P(A \mid B) = \frac{P(B \mid A)P(A)}{P(B)}</code></pre><script type="math/tex; mode=display">P(A \mid B) = \frac{P(B \mid A)P(A)}{P(B)}</script><p><code class="MathJax_Preview">P(A)</code><script type="math/tex">P(A)</script> 는 A의 prior로, 사건 B에 대한 어떠한 정보를 알지 못하는 것을 의미한다. <code class="MathJax_Preview">P(A \mid B)</code><script type="math/tex">P(A \mid B)</script> 는 B의 값이 주어진 경우 A의 posterior이다. <code class="MathJax_Preview">P(B \mid A)</code><script type="math/tex">P(B \mid A)</script> 는 A가 주어졌을 때 B의 조건부 확률이다.<p>bayes 정리의 자세한 내용은 <a href="https://ko.wikipedia.org/wiki/%EB%B2%A0%EC%9D%B4%EC%A6%88_%EC%A0%95%EB%A6%AC">wiki</a>를 참고한다.<h3 id="recursive-bayes-filter">Recursive bayes filter</h3><p>위에서 설명한 state estimation은 bayes filter의 과정으로 설명할 수 있으며, 각 step의 state를 반복적으로 계산함으로써 계산할 수 있기 때문에 recursive bayes filter로 부른다. 전체적인 recursive bayes filter의 식은 다음과 같다.<pre class="MathJax_Preview"><code>\begin{aligned}
bel(x_t) &amp;= p(x_t \mid z_{1:t},u_{1:t}) \\
       &amp;= \eta p(z_t \mid x_t, z_{1:t-1}, u_{1:t})p(x_t \mid z_{1:t-1},u_{1:t}) \\
       &amp;= \eta p(z_t \mid x_t)p(x_t \mid z_{1:t-1},u_{1:t}) \\
       &amp;= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, z_{1:t-1}, u_{1:t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t}) dx_{t-1}\\
       &amp;= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t}) dx_{t-1}\\
       &amp;= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t-1}) dx_{t-1}\\
       &amp;= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t}) bel(x_{t-1}) dx_{t-1}\\
\end{aligned}</code></pre><script type="math/tex; mode=display">% <![CDATA[ \begin{aligned} bel(x_t) &= p(x_t \mid z_{1:t},u_{1:t}) \\ &= \eta p(z_t \mid x_t, z_{1:t-1}, u_{1:t})p(x_t \mid z_{1:t-1},u_{1:t}) \\ &= \eta p(z_t \mid x_t)p(x_t \mid z_{1:t-1},u_{1:t}) \\ &= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, z_{1:t-1}, u_{1:t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t}) dx_{t-1}\\ &= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t}) dx_{t-1}\\ &= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t-1}) dx_{t-1}\\ &= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t}) bel(x_{t-1}) dx_{t-1}\\ \end{aligned} %]]></script><p>위의 식은 recursive bayes filter를 유도하는 과정을 모두 표현하고 있기 때문에 다소 복잡해 보인다. 우선 전체적인 식을 이해하기 위해서 맨 처음과 맨 마지막 식만을 보면 다음과 같다.<pre class="MathJax_Preview"><code>\begin{aligned}
bel(x_t)  &amp;= p(x_t \mid z_{1:t},u_{1:t}) \\
          &amp;= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t}) bel(x_{t-1}) dx_{t-1}\\
\end{aligned}</code></pre><script type="math/tex; mode=display">% <![CDATA[ \begin{aligned} bel(x_t) &= p(x_t \mid z_{1:t},u_{1:t}) \\ &= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t}) bel(x_{t-1}) dx_{t-1}\\ \end{aligned} %]]></script><p><code class="MathJax_Preview">bel(x_t)</code><script type="math/tex">bel(x_t)</script> 는 처음부터 현재까지의 observation( <code class="MathJax_Preview">z</code><script type="math/tex">z</script> )와 control input( <code class="MathJax_Preview">u</code><script type="math/tex">u</script> )을 알고 있을 때 현재 state( <code class="MathJax_Preview">x_t</code><script type="math/tex">x_t</script> )의 확률을 의미한다. 위의 식에서 <code class="MathJax_Preview">bel(x_t)</code><script type="math/tex">bel(x_t)</script> 의 식은 <code class="MathJax_Preview">bel(x_{t-1})</code><script type="math/tex">bel(x_{t-1})</script> 의 integral로 표현되어 있기 때문에 만약 <code class="MathJax_Preview">p(z_t \mid x_t)</code><script type="math/tex">p(z_t \mid x_t)</script> 와 <code class="MathJax_Preview">p(x_t \mid x_{t-1}, u_t)</code><script type="math/tex">p(x_t \mid x_{t-1}, u_t)</script> 에 대한 정보를 알고 있다면 반복적인 계산을 통해 현재 state의 확률을 계산할 수 있음을 알 수 있다. 여기서 <code class="MathJax_Preview">p(z_t \mid x_t)</code><script type="math/tex">p(z_t \mid x_t)</script> 는 현재의 state에서 센서 데이터의 확률인 observation model이며, <code class="MathJax_Preview">p(x_t \mid x_{t-1}, u_t)</code><script type="math/tex">p(x_t \mid x_{t-1}, u_t)</script> 은 현재의 control input에 대해 이전 state에서 현재 state로의 update를 나타내는 motion model를 의미한다. 위의 식을 Recursive bayes filter라고 한다. Recursive bayes filter는 Kalman filter의 기본이 되는 식이다. 다음은 recursive bayes filter의 유도과정을 간단하게 살펴본다. 유도에 관심이 없고 전체적인 흐름만 보고자 한다면 다음 설명은 넘어가도 좋다.<h4 id="recursive-bayes-filter의-유도과정">Recursive bayes filter의 유도과정</h4><pre class="MathJax_Preview"><code>\begin{aligned}
bel(x_t) &amp;= p(x_t \mid z_{1:t},u_{1:t}) \\
\end{aligned}</code></pre><script type="math/tex; mode=display">% <![CDATA[ \begin{aligned} bel(x_t) &= p(x_t \mid z_{1:t},u_{1:t}) \\ \end{aligned} %]]></script><p>control input과 observation을 알고 있을 때 현재 state의 확률을 의미하는 belief의 정의<pre class="MathJax_Preview"><code>\begin{aligned}
bel(x_t) &amp;= p(x_t \mid z_{1:t},u_{1:t}) \\
       &amp;= \eta p(z_t \mid x_t, z_{1:t-1}, u_{1:t})p(x_t \mid z_{1:t-1},u_{1:t}) \\
\end{aligned}</code></pre><script type="math/tex; mode=display">% <![CDATA[ \begin{aligned} bel(x_t) &= p(x_t \mid z_{1:t},u_{1:t}) \\ &= \eta p(z_t \mid x_t, z_{1:t-1}, u_{1:t})p(x_t \mid z_{1:t-1},u_{1:t}) \\ \end{aligned} %]]></script><p>기본적인 bayes rule이다. 현재 시점 t의 observation은 현재의 state에서 얻어진 data이므로 따로 분리하여 위와 같이 정의한다. <code class="MathJax_Preview">p(x_t \mid z_{1:t-1},u_{1:t})</code><script type="math/tex">p(x_t \mid z_{1:t-1},u_{1:t})</script> 는 t시점까지의 control input, 그리고 t-1시점 까지의 observation을 알고 있을 때의 현재 시점 t의 state, <code class="MathJax_Preview">p(z_t \mid x_t, z_{1:t-1}, u_{1:t})</code><script type="math/tex">p(z_t \mid x_t, z_{1:t-1}, u_{1:t})</script> 는 현재 state에서 얻어진 observation의 확률이다. <code class="MathJax_Preview">\eta</code><script type="math/tex">\eta</script> 는 normalize term이다.<pre class="MathJax_Preview"><code>\begin{aligned}
bel(x_t)
       &amp;= \eta p(z_t \mid x_t, z_{1:t-1}, u_{1:t})p(x_t \mid z_{1:t-1},u_{1:t}) \\
       &amp;= \eta p(z_t \mid x_t)p(x_t \mid z_{1:t-1},u_{1:t}) \\
\end{aligned}</code></pre><script type="math/tex; mode=display">% <![CDATA[ \begin{aligned} bel(x_t) &= \eta p(z_t \mid x_t, z_{1:t-1}, u_{1:t})p(x_t \mid z_{1:t-1},u_{1:t}) \\ &= \eta p(z_t \mid x_t)p(x_t \mid z_{1:t-1},u_{1:t}) \\ \end{aligned} %]]></script><p>Markov Assumption은 현재의 state는 바로 이전 state에 의해서만 영향을 받는다는 것이다. 즉 이전 state를 결정하기 위한 데이터들은 알지 못해도 이전 state만 알고 있다면 현재 state를 결정할 수 있다는 것이다. Markov assumtion에 의해 <code class="MathJax_Preview">p(z_t \mid x_t, z_{1:t-1}, u_{1:t})</code><script type="math/tex">p(z_t \mid x_t, z_{1:t-1}, u_{1:t})</script> 는 <code class="MathJax_Preview">p(z_t \mid x_t)</code><script type="math/tex">p(z_t \mid x_t)</script>로 표현 할 수 있다. 왜냐하면 현재의 observation은 현재의 state인 <code class="MathJax_Preview">x_t</code><script type="math/tex">x_t</script>에만 영향을 받으며, <code class="MathJax_Preview">z_{1:t-1}</code><script type="math/tex">z_{1:t-1}</script> 와 <code class="MathJax_Preview">u_{1:t}</code><script type="math/tex">u_{1:t}</script>는 현재 state <code class="MathJax_Preview">x_t</code><script type="math/tex">x_t</script>에만 영향을 미치기 때문이다.<pre class="MathJax_Preview"><code>\begin{aligned}
bel(x_t)
       &amp;= \eta p(z_t \mid x_t)p(x_t \mid z_{1:t-1},u_{1:t}) \\
       &amp;= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, z_{1:t-1}, u_{1:t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t}) dx_{t-1}\\
\end{aligned}</code></pre><script type="math/tex; mode=display">% <![CDATA[ \begin{aligned} bel(x_t) &= \eta p(z_t \mid x_t)p(x_t \mid z_{1:t-1},u_{1:t}) \\ &= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, z_{1:t-1}, u_{1:t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t}) dx_{t-1}\\ \end{aligned} %]]></script><p>다음 식은 total probability(전체확률) 법칙에 의해 위와같이 전개된다. 전체확률 법칙은 간단하게 표현하면 다음과 같다.<pre class="MathJax_Preview"><code>P(A) = \int_B P(A \mid B)P(B) dB</code></pre><script type="math/tex; mode=display">P(A) = \int_B P(A \mid B)P(B) dB</script><p>즉 A는 <code class="MathJax_Preview">x_t</code><script type="math/tex">x_t</script> 이며, B는 <code class="MathJax_Preview">x_{t-1}</code><script type="math/tex">x_{t-1}</script> 이다.<pre class="MathJax_Preview"><code>\begin{aligned}
bel(x_t)
       &amp;= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, z_{1:t-1}, u_{1:t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t}) dx_{t-1}\\
       &amp;= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t}) dx_{t-1}\\
\end{aligned}</code></pre><script type="math/tex; mode=display">% <![CDATA[ \begin{aligned} bel(x_t) &= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, z_{1:t-1}, u_{1:t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t}) dx_{t-1}\\ &= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t}) dx_{t-1}\\ \end{aligned} %]]></script><p>위 과정은 앞에서 설명한 Markov assumtion에 의해서 <code class="MathJax_Preview">x_t</code><script type="math/tex">x_t</script> 에 영향을 미치는 <code class="MathJax_Preview">x_{t-1}</code><script type="math/tex">x_{t-1}</script> 과 <code class="MathJax_Preview">u_t</code><script type="math/tex">u_t</script>만 남기고 정리된다.<pre class="MathJax_Preview"><code>\begin{aligned}
bel(x_t)
       &amp;= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t}) dx_{t-1}\\
       &amp;= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t-1}) dx_{t-1}\\
\end{aligned}</code></pre><script type="math/tex; mode=display">% <![CDATA[ \begin{aligned} bel(x_t) &= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t}) dx_{t-1}\\ &= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t-1}) dx_{t-1}\\ \end{aligned} %]]></script><p>이 과정 또한 Markov assumption으로 <code class="MathJax_Preview">p(x_{t-1} \mid z_{1:t-1}, u_{1:t})</code><script type="math/tex">p(x_{t-1} \mid z_{1:t-1}, u_{1:t})</script> 에서 <code class="MathJax_Preview">u_t</code><script type="math/tex">u_t</script>는 t-1시점의 state인 <code class="MathJax_Preview">x_{t-1}</code><script type="math/tex">x_{t-1}</script> 에 영향을 미치지 않기 때문에 제거 될 수 있다.<pre class="MathJax_Preview"><code>\begin{aligned}
bel(x_t)
       &amp;= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t-1}) dx_{t-1}\\
       &amp;= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t}) bel(x_{t-1}) dx_{t-1}\\
\end{aligned}</code></pre><script type="math/tex; mode=display">% <![CDATA[ \begin{aligned} bel(x_t) &= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t-1}) dx_{t-1}\\ &= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t}) bel(x_{t-1}) dx_{t-1}\\ \end{aligned} %]]></script><p>따라서 위와 같은 과정을 통해 최종적으로 식은 위와같이 정리되며, recursive bayes filter의 식으로 정리된다.<p><strong>본 글을 참조하실 때에는 출처 명시 부탁드립니다.</strong></article><aside class="comments" role="complementary"><h2>Comments</h2><div id="disqus_thread"></div><script> /* var disqus_config = function () { this.page.url = 'http://localhost:4000http://JinyongJeong.github.io/2017/02/13/lec01_SLAM_bayes_filter/'; this.page.identifier = '/2017/02/13/lec01_SLAM_bayes_filter/'; }; */ var loaded = false; var disqus_thread_offsetTop = document.getElementById('disqus_thread').offsetTop; window.addEventListener('scroll', function (e) { if (!loaded && document.body.scrollTop + window.innerHeight >= disqus_thread_offsetTop) { loaded = true; var d = document, s = d.createElement('script'); s.src = '//jinyongjeong.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); } }); </script> <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript></aside><aside class="related" role="complementary"><h2>Related Posts</h2><ul class="related-posts"><li> <a href="http://JinyongJeong.github.io/2017/02/15/lec04_EKF_example/"> <span>[SLAM] Extended Kalman Filter(EKF) 예제</span> <small><time datetime="2017-02-15T00:00:00+09:00"> 02/15/17 </time></small> </a><li> <a href="http://JinyongJeong.github.io/2017/02/14/lec03_kalman_filter_and_EKF/"> <span>[SLAM] Kalman filter and EKF(Extended Kalman Filter)</span> <small><time datetime="2017-02-14T00:00:00+09:00"> 02/14/17 </time></small> </a><li> <a href="http://JinyongJeong.github.io/2017/02/14/lec02_motion_observation_model/"> <span>[SLAM] Motion & Observation model</span> <small><time datetime="2017-02-14T00:00:00+09:00"> 02/14/17 </time></small> </a></ul></aside><aside class="author" role="complementary"><h2>About</h2><img class="me" alt="Jinyong Jeong" src="/images/about/profile.jpg" srcset="/images/about/profile.jpg 2x" /><h3 id="jinyong-jeong">Jinyong Jeong</h3><p>[Current]<ul><li>ph.D student<li>Civil and Environmental Engineering(CEE)<li>Korea Advanced Institute of Science and Technology(<a href="http://www.kaist.ac.kr">KAIST</a>)<li>Intelligent Robotic Autonomy and Perception(<a href="http://irap.kaist.ac.kr">IRAP</a>)<li>Research Interest: Autonomous car, SLAM, computer Vision</ul><p>[Previous]<ul><li>2005.02 ~ 2012.08 : Inha university (undergraduate course)<li>2012.08 ~ 2014.08 : KAIST (master course)<li>2014.08 ~ 2015.10 : Defense Agency for Technology and Quality (DTaQ) researcher<li>2016.02 ~ current : KAIST (ph.D course)</ul></aside></main><div id="_backdrop" class="backdrop"></div><header id="_sidebar" class="sidebar" role="banner"><div id="_asidebar" class="container sidebar-sticky"><div class="sidebar-about"><h1 class="font-accent"><a href="http://JinyongJeong.github.io/">Jinyong Jeong</a></h1><p>This blog is to remember what I studied.</div><nav class="sidebar-nav font-accent" role="navigation"><ul><li> <a class="sidebar-nav-item " href="http://JinyongJeong.github.io/tag/post/">All post</a><li> <a class="sidebar-nav-item " href="http://JinyongJeong.github.io/tag/SLAM/">SLAM</a><li> <a class="sidebar-nav-item " href="http://JinyongJeong.github.io/tag/ubuntu/">Ubuntu</a><li> <a class="sidebar-nav-item " href="http://JinyongJeong.github.io/tag/jekyll/">Jekyll</a><li> <a class="sidebar-nav-item " href="http://JinyongJeong.github.io/tag/software/">Software</a><li> <a class="sidebar-nav-item " href="http://JinyongJeong.github.io/tag/math/">Math</a><li> <a class="sidebar-nav-item " href="http://JinyongJeong.github.io/tag/IRAP/">IRAP</a><li> <a class="sidebar-nav-item " href="http://JinyongJeong.github.io/about/">About</a></ul></nav><div class="sidebar-social"><ul><li> <a href="https://facebook.com/jinyong.jeong.399"> <span class="icon-facebook"></span> <span class="sr-only">facebook</span> </a><li> <a href="https://www.youtube.com/channel/UCPuPw9OXrBzYue3Sv4uvVxQ"> <span class="icon-youtube"></span> <span class="sr-only">youtube</span> </a><li> <a href="https://github.com/JinyongJeong"> <span class="icon-github"></span> <span class="sr-only">github</span> </a></ul></div></div></header><!--[if gt IE 8]><!----> <script>loadJSDeferred('http://JinyongJeong.github.io/public/js/hydejack.min.js')</script> <script> WebFontConfig = { google: { families: 'Roboto+Slab:700|PT+Serif:400,400italic,700,700italic'.split('|') }, custom: { families: ['icomoon'], urls: ['http://JinyongJeong.github.io/public/css/icons.css'] }, classes: false, events: false }; </script> <script>loadJSDeferred('https://ajax.googleapis.com/ajax/libs/webfont/1.6.16/webfont.js')</script> <script> window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date; ga('create', 'UA-84025722-2', 'auto'); ga('send', 'pageview'); </script> <script>loadJSDeferred('https://www.google-analytics.com/analytics.js')</script> <!--<![endif]-->
