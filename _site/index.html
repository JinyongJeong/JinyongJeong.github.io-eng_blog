<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no"><title>Blog &middot; Jinyong Jeong</title><!--[if gt IE 8]><!----><style> article,aside,dialog,figcaption,figure,footer,header,hgroup,main,nav,section{display:block}mark{background:#FF0;color:#000}template{display:none}*{-webkit-box-sizing:border-box;-moz-box-sizing:border-box;box-sizing:border-box}html,body{margin:0;padding:0}html{line-height:1.65}body{color:#515151;background-color:#fff}a{text-decoration:none}img{display:block;max-width:100%;margin:0 0 1rem}img.lead{max-width:calc(100% + 2rem);width:calc(100% + 2rem);margin-left:calc(-1rem);margin-right:calc(-1rem)}h1,h2,h3,h4,h5,h6{margin-bottom:.5rem;font-weight:600;line-height:1.25;color:#313131;text-rendering:optimizeLegibility}h1{font-size:2rem}h2{margin-top:1rem;font-size:1.5rem}p{margin-top:0;margin-bottom:1rem}p.lead{font-size:1.25rem;font-weight:300}ul,ol,dl{margin-top:0;margin-bottom:1rem}hr{position:relative;margin:1.5rem 0;border:0;border-top:1px solid #eee;border-bottom:1px solid #fff}.container{max-width:38rem;padding-left:1rem;padding-right:1rem;margin-left:auto;margin-right:auto}.page-title,.post-title{color:#303030}.page-title,.post-title{margin-top:0}.post-date{display:block;margin-top:-.25rem;margin-bottom:1rem;color:#9a9a9a;font-weight:bold}.related{padding-top:2rem;padding-bottom:2rem}.related-posts{padding-left:0;list-style:none}.related-posts>li{margin-top:1rem}.related-posts>li>*{font-weight:normal}.message{margin-bottom:1rem;padding:1rem;color:#717171;background-color:#f9f9f9;margin-left:-1rem;margin-right:-1rem}body{padding-left:0.5rem}@media (min-width: 48em){html{font-size:16px}body{padding-left:0}}@media (min-width: 58em){html{font-size:18px}}.sr-only{display:none}.backdrop{display:none}.sidebar{position:relative;z-index:4;padding:2rem 1rem;color:rgba(255,255,255,0.75);background-color:#202020;text-align:left;background-size:cover;background-position:center center;min-height:640px;min-height:100vh;margin-left:-0.5rem}.sidebar a{color:#fff}.sidebar ul{list-style:none;padding-left:0}.sidebar-sticky{position:absolute;right:1rem;bottom:1rem;left:1rem}.sidebar-about>h1{color:#fff;font-size:2rem}.sidebar-nav-item{font-weight:bold;display:block;line-height:1.75;padding:.25rem .1rem;border-top:1px solid rgba(255,255,255,0.23)}.sidebar-social>ul{min-height:3.5rem}.sidebar::before{content:"";position:absolute;top:0;left:0;bottom:0;right:0;background:rgba(32,32,32,0.33);background:-moz-linear-gradient(bottom, rgba(32,32,32,0) 0%, rgba(32,32,32,0.5) 100%);background:-webkit-linear-gradient(bottom, rgba(32,32,32,0) 0%, rgba(32,32,32,0.5) 100%);background:linear-gradient(to bottom, rgba(32,32,32,0) 0%, rgba(32,32,32,0.5) 100%)}@media (min-width: 48em){.sidebar{position:fixed;top:0;left:0;bottom:0;width:18rem;margin-left:0}}.menu{display:block;padding:1.25rem 1.5rem;color:#9a9a9a;border-bottom:none;position:fixed;top:0;left:0;z-index:2}@media (min-width: 48em){.menu{position:absolute;left:-9999px}}@media (min-width: 48em){.menu:focus{left:19.5rem}}@media (min-width: 64em){.menu:focus{left:21.5rem}}.content{padding-top:4rem;padding-bottom:4rem}@media (min-width: 48em){.content{max-width:38rem;margin-left:20rem;margin-right:2rem;border-left:none}}@media (min-width: 64em){.content{margin-left:22rem;margin-right:4rem}}.me{float:right;width:6.5rem;margin-top:-4.8rem;margin-left:1rem;border-radius:100%;position:relative}@media (min-width: 38em){.me{width:7rem;margin-top:-5.05rem}}@media (min-width: 48em){.me{width:6.5rem;margin-top:-4.8rem}}@media (min-width: 58em){.me{width:7rem;margin-top:-5.05rem}}</style><noscript><link rel="stylesheet" href="http://JinyongJeong.github.io/public/css/non-essentials.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Slab:700|PT+Serif:400,400italic,700,700italic"><link rel="stylesheet" href="http://JinyongJeong.github.io/public/css/icons.css"> </noscript><link rel="preload" href="http://JinyongJeong.github.io/public/css/non-essentials.css" as="style" onload="this.rel='stylesheet'"><style> html { font-family: "PT Serif", Georgia, serif; } :focus { outline-color: #A85641; } .font-accent { font-family: "Roboto Slab", "PT Serif", Georgia, serif; } .content a, .related-posts li a:hover { color: #A85641; } ::selection { color: #fff; background: #A85641; } ::-moz-selection { color: #fff; background: #A85641; } .sidebar { background-image: url('/public/img/6.jpg'); }</style><!--<![endif]--><link rel="canonical" href="http://localhost:4000http://JinyongJeong.github.io/" /><link rel="alternate" type="application/atom+xml" title="Jinyong Jeong Atom Feed" href="http://JinyongJeong.github.io/atom.xml"> <script>!function(n,e){function t(n,e){n.onload=function(){this.onerror=this.onload=null,e(null,n)},n.onerror=function(){this.onerror=this.onload=null,e(new Error("Failed to load "+this.src),n)}}function o(n,e){n.onreadystatechange=function(){"complete"!=this.readyState&&"loaded"!=this.readyState||(this.onreadystatechange=null,e(null,n))}}n.isReady=!1,n.loadJSDeferred=function(a,r){function d(){n.isReady=!0;var d=e.createElement("script");d.src=a,r&&(("onload"in d?t:o)(d,r),d.onload||t(d,r));var i=e.getElementsByTagName("script")[0];i.parentNode.insertBefore(d,i)}n.isReady?d():n.addEventListener?n.addEventListener("load",d,!1):n.attachEvent?n.attachEvent("onload",d):n.onload=d}}(window,document); </script> <!--[if lt IE 9]> <script src="https://unpkg.com/html5shiv/dist/html5shiv.min.js"></script> <![endif]--><body> <span class="sr-only">Jump to:</span> <a id="_menu" class="menu" href="#_asidebar"> <span>☰</span> <span class="sr-only">Menu</span> </a><main class="content container" role="main"><article id="post-2017/02/15/lec04_EKF_example" class="post" role="article"><h1 class="post-title"> <a href="http://JinyongJeong.github.io/2017/02/15/lec04_EKF_example/"> [SLAM] Extended Kalman Filter(EKF) 예제 </a></h1><div class="post-date"> <time datetime="2017-02-15T00:00:00+09:00">02/15/17</time> <span>on <a href="http://JinyongJeong.github.io/tag/SLAM/">SLAM</a></span></div><p class="message">Robot의 실제 모델을 이용하여 EKF를 설명.<hr/><p><strong>본 글은 University Freiburg의 <a href="http://ais.informatik.uni-freiburg.de/teaching/ws13/mapping/">Robot Mapping</a> 강의를 바탕으로 이해하기 쉽도록 정리하려는 목적으로 작성되었습니다. 개인적인 의견을 포함하여 작성되기 때문에 틀린 내용이 있을 수도 있습니다. 틀린 부분은 지적해주시면 확인 후 수정하겠습니다.</strong><p>이번 글에서는 이전 글에서 설명한 Extended Kalman Filter(EKF)를 실제 모델을 이용해서 설명한다. 이전 글을 통해 EKF의 선형화 과정과 bayes filter 과정을 이해했지만 실제 어떻게 적용을 하는지에 대해서는 이해가 잘 되지 않을 수 있다. 이 글에서는 velocity motion model과 observation model을 이용하여 EKF과정을 설명한다.<h3 id="motion-model">Motion model</h3><p>Robot의 Motion model은 크게 두가지로 나뉜다.<ul><li>Odometry-based model<li>Velocity-based model</ul><p>이 글에서는 velocity-based model을 이용하여 설명한다. 아래 그림은 velocity-based model을 보여준다. <code class="MathJax_Preview">x,y,\theta</code><script type="math/tex">x,y,\theta</script>는 로봇의 x,y좌표 및 방향을 의미하며, 로봇의 선속도는 <code class="MathJax_Preview">v</code><script type="math/tex">v</script>, 각속도는 <code class="MathJax_Preview">\omega</code><script type="math/tex">\omega</script>이다.<p><img align="middle" src="/images/post/SLAM/lec04_EKF_example/velocity_model.png" width="100%" /><p>이때 로봇의 상태(state)는 <code class="MathJax_Preview">\mathbf{x_t} = \begin{bmatrix} x \\ y \\ \theta \end{bmatrix}</code><script type="math/tex">\mathbf{x_t} = \begin{bmatrix} x \\ y \\ \theta \end{bmatrix}</script>이며, control input은 <code class="MathJax_Preview">u_t = \begin{bmatrix} v \\ \omega \end{bmatrix}</code><script type="math/tex">u_t = \begin{bmatrix} v \\ \omega \end{bmatrix}</script>이다. 실제 로봇을 이동시키기 위해서는 모터를 구동시켜야 하기 때문에 로봇에 들어가는 실제 입력은 모터를 구동하기 위한 제어값이다. 하지만 여기서 control input은 로봇이 얼마나 이동했는지를 측정하기 위한 센서값을 의미한다. Velocity-based model에서 motion model은 다음과 같다.<pre class="MathJax_Preview"><code>\begin{bmatrix}
x_{t}\\y_{t}\\ \theta_{t}
\end{bmatrix}
=
\begin{bmatrix}
x_{t-1} - \frac{\hat{v_t}}{\hat{\omega_t}} \sin \theta_{t-1} + \frac{\hat{v_t}}{\hat{\omega_t}}\sin(\theta_{t-1} + \hat{\omega_t}\vartriangle t)\\
y_{t-1} - \frac{\hat{v_t}}{\hat{\omega_t}} \cos \theta_{t-1} - \frac{\hat{v_t}}{\hat{\omega_t}}\cos(\theta_{t-1} + \hat{\omega_t}\vartriangle t)\\
\theta_{t-1} + \hat{\omega_t} \vartriangle t
\end{bmatrix}</code></pre><script type="math/tex; mode=display">\begin{bmatrix} x_{t}\\y_{t}\\ \theta_{t} \end{bmatrix} = \begin{bmatrix} x_{t-1} - \frac{\hat{v_t}}{\hat{\omega_t}} \sin \theta_{t-1} + \frac{\hat{v_t}}{\hat{\omega_t}}\sin(\theta_{t-1} + \hat{\omega_t}\vartriangle t)\\ y_{t-1} - \frac{\hat{v_t}}{\hat{\omega_t}} \cos \theta_{t-1} - \frac{\hat{v_t}}{\hat{\omega_t}}\cos(\theta_{t-1} + \hat{\omega_t}\vartriangle t)\\ \theta_{t-1} + \hat{\omega_t} \vartriangle t \end{bmatrix}</script><p>즉 velocity-based model은 비선형 함수로 정의된다. 위 식에서 <code class="MathJax_Preview">\hat{}</code><script type="math/tex">\hat{}</script>은 노이즈를 포함한 control input을 의미한다. control input의 covariance가 <code class="MathJax_Preview">M_t</code><script type="math/tex">M_t</script>일 때 다음과 같이 노이즈를 분리할 수 있다.<pre class="MathJax_Preview"><code>\begin{bmatrix} \hat{v} \\ \hat{\omega} \end{bmatrix}
=
\begin{bmatrix} v \\ \omega \end{bmatrix}+\mathcal{N}(0,M_t)</code></pre><script type="math/tex; mode=display">\begin{bmatrix} \hat{v} \\ \hat{\omega} \end{bmatrix} = \begin{bmatrix} v \\ \omega \end{bmatrix}+\mathcal{N}(0,M_t)</script><p>따라서 노이즈 항을 따로 분리하면 다음과 같이 다시 쓸 수 있다.<pre class="MathJax_Preview"><code>\begin{bmatrix}
x_{t}\\y_{t}\\ \theta_{t}
\end{bmatrix}
=
\begin{bmatrix}
x_{t-1} - \frac{v_t}{\omega_t} \sin \theta_{t-1} + \frac{v_t}{\omega_t}\sin(\theta_{t-1} + \omega_t\vartriangle t)\\
y_{t-1} + \frac{v_t}{\omega_t} \cos \theta_{t-1} - \frac{v_t}{\omega_t}\cos(\theta_{t-1} + \omega_t\vartriangle t)\\
\theta_{t-1} + \omega_t \vartriangle t
\end{bmatrix} + \mathcal{N}(0,R_t)</code></pre><script type="math/tex; mode=display">\begin{bmatrix} x_{t}\\y_{t}\\ \theta_{t} \end{bmatrix} = \begin{bmatrix} x_{t-1} - \frac{v_t}{\omega_t} \sin \theta_{t-1} + \frac{v_t}{\omega_t}\sin(\theta_{t-1} + \omega_t\vartriangle t)\\ y_{t-1} + \frac{v_t}{\omega_t} \cos \theta_{t-1} - \frac{v_t}{\omega_t}\cos(\theta_{t-1} + \omega_t\vartriangle t)\\ \theta_{t-1} + \omega_t \vartriangle t \end{bmatrix} + \mathcal{N}(0,R_t)</script><p>여기서 <code class="MathJax_Preview">R_t</code><script type="math/tex">R_t</script>는 process noise로 control input의 uncertainty에 의해 발생하며, <code class="MathJax_Preview">R_t</code><script type="math/tex">R_t</script>에 대해서는 뒤에서 다시 자세히 설명한다.<p>이제 motion model을 알고 있으므로 앞에서 설명한 Jacobian matrix를 이용하여 선형화된 model을 계산할 수 있다.<pre class="MathJax_Preview"><code>\mathbf{x_t} = G_t \mathbf{x_{t-1}} + V_t \mathbf{u_t}</code></pre><script type="math/tex; mode=display">\mathbf{x_t} = G_t \mathbf{x_{t-1}} + V_t \mathbf{u_t}</script><p>위 식에서 <code class="MathJax_Preview">G_t, V_t</code><script type="math/tex">G_t, V_t</script>는 각각 <code class="MathJax_Preview">\mathbf{x_{t-1}}</code><script type="math/tex">\mathbf{x_{t-1}}</script>와 <code class="MathJax_Preview">\mathbf{u_t}</code><script type="math/tex">\mathbf{u_t}</script>로 편미분을 통해 계산한 Jacobian matrix이다.<pre class="MathJax_Preview"><code>G_t = \frac{\partial g(u_t,\mu_{t-1})}{\partial \mathbf{x_{t-1}}} =
\begin{pmatrix}
1 &amp; 0 &amp; -\frac{v_t}{\omega_t}\cos \theta_{t-1} + \frac{v_t}{\omega_t}\cos(\theta_{t-1}+\omega_t \vartriangle t)\\
0 &amp; 1 &amp; -\frac{v_t}{\omega_t}\sin \theta_{t-1} + \frac{v_t}{\omega_t}\sin(\theta_{t-1}+\omega_t \vartriangle t)\\
0 &amp; 0 &amp; 1
\end{pmatrix}</code></pre><script type="math/tex; mode=display">% <![CDATA[ G_t = \frac{\partial g(u_t,\mu_{t-1})}{\partial \mathbf{x_{t-1}}} = \begin{pmatrix} 1 & 0 & -\frac{v_t}{\omega_t}\cos \theta_{t-1} + \frac{v_t}{\omega_t}\cos(\theta_{t-1}+\omega_t \vartriangle t)\\ 0 & 1 & -\frac{v_t}{\omega_t}\sin \theta_{t-1} + \frac{v_t}{\omega_t}\sin(\theta_{t-1}+\omega_t \vartriangle t)\\ 0 & 0 & 1 \end{pmatrix} %]]></script><pre class="MathJax_Preview"><code>V_t = \frac{\partial g(u_t,\mu_{t-1})}{\partial \mathbf{u_{t}}} =
\begin{pmatrix}
\frac{-\sin \theta_{t-1} + \sin (\theta_{t-1}+\omega_t \vartriangle t)}{\omega_t} &amp; \frac{v_t(\sin \theta_{t-1} - \sin (\theta_{t-1}+\omega_t \vartriangle t))}{\omega_t^2} + \frac{v_t \vartriangle t \cos (\theta_{t-1} + \omega_t \vartriangle t)}{\omega_t}\\
\frac{\cos \theta_{t-1} - \cos (\theta_{t-1}+\omega_t \vartriangle t)}{\omega_t} &amp;
\frac{v_t(-\cos \theta_{t-1} + \cos (\theta_{t-1}+\omega_t \vartriangle t))}{\omega_t^2} + \frac{v_t \vartriangle t \sin (\theta_{t-1} + \omega_t \vartriangle t)}{\omega_t}
\end{pmatrix}</code></pre><script type="math/tex; mode=display">% <![CDATA[ V_t = \frac{\partial g(u_t,\mu_{t-1})}{\partial \mathbf{u_{t}}} = \begin{pmatrix} \frac{-\sin \theta_{t-1} + \sin (\theta_{t-1}+\omega_t \vartriangle t)}{\omega_t} & \frac{v_t(\sin \theta_{t-1} - \sin (\theta_{t-1}+\omega_t \vartriangle t))}{\omega_t^2} + \frac{v_t \vartriangle t \cos (\theta_{t-1} + \omega_t \vartriangle t)}{\omega_t}\\ \frac{\cos \theta_{t-1} - \cos (\theta_{t-1}+\omega_t \vartriangle t)}{\omega_t} & \frac{v_t(-\cos \theta_{t-1} + \cos (\theta_{t-1}+\omega_t \vartriangle t))}{\omega_t^2} + \frac{v_t \vartriangle t \sin (\theta_{t-1} + \omega_t \vartriangle t)}{\omega_t} \end{pmatrix} %]]></script><p>따라서 위에서 계산한 Jacobian matrix을 이용하여 EKF의 prediction step을 다음과 같이 계산할 수 있다.<pre class="MathJax_Preview"><code>\bar{\Sigma_t} = G_t \Sigma_{t-1} G_t^T + V_t M_t V_t^T = G_t \Sigma_{t-1} G_t^T + R_t</code></pre><script type="math/tex; mode=display">\bar{\Sigma_t} = G_t \Sigma_{t-1} G_t^T + V_t M_t V_t^T = G_t \Sigma_{t-1} G_t^T + R_t</script><h3 id="observation-model">Observation model</h3><p>비선형 observation model을 EKF에 적용해 보기 위해서 가상의 로봇을 이용한다. 이 로봇은 3개의 센서를 갖고 있다. 첫번째 센서는 로봇의 위치에서 부터 landmark까지의 euclidean distance를 측정할 수 있다. 두번째, 세번째 센서는 landmark까지의 x방향의 거리와 y방향의 거리를 각각 측정할 수 있다. 로봇의 state는 <code class="MathJax_Preview">\mathbf{\bar{x}_t} = \begin{bmatrix} \bar{x}_t \\ \bar{y}_t \\ \bar{\theta}_t \end{bmatrix}</code><script type="math/tex">\mathbf{\bar{x}_t} = \begin{bmatrix} \bar{x}_t \\ \bar{y}_t \\ \bar{\theta}_t \end{bmatrix}</script>로 표시하며, landmark의 위치는 <code class="MathJax_Preview">\mathbf{m} = \begin{bmatrix} m_x\\m_y \end{bmatrix}</code><script type="math/tex">\mathbf{m} = \begin{bmatrix} m_x\\m_y \end{bmatrix}</script>라고 하자. 이때의 각 센서의 데이터입력 <code class="MathJax_Preview">\mathbf{z}</code><script type="math/tex">\mathbf{z}</script>는 다음과 같다.<pre class="MathJax_Preview"><code>\mathbf{z_t} =
\begin{bmatrix}
z_1\\z_2\\z_3
\end{bmatrix}
=
\begin{bmatrix}
\sqrt{(m_x - x_t)^2+(m_y - y_t)^2}\\
m_x - x_t\\
m_y - y_t
\end{bmatrix}</code></pre><script type="math/tex; mode=display">\mathbf{z_t} = \begin{bmatrix} z_1\\z_2\\z_3 \end{bmatrix} = \begin{bmatrix} \sqrt{(m_x - x_t)^2+(m_y - y_t)^2}\\ m_x - x_t\\ m_y - y_t \end{bmatrix}</script><p>따라서 위 비선형 observation model을 선형화 하기 위해서 Jacobian을 구하면 다음과 같다.<pre class="MathJax_Preview"><code>H_t = \frac{\partial \mathbf{z_t}}{\partial \mathbf{\bar{x}_t}} =
\begin{pmatrix}
\frac{-m_x+\bar{x}_t}{\sqrt{(m_x-\bar{x}_t)^2 + (m_y-\bar{y}_t)^2}} &amp; \frac{-m_y+\bar{y}_t}{\sqrt{(m_x-\bar{x}_t)^2 + (m_y-\bar{y}_t)^2}} &amp; 0 \\
-1 &amp; 0 &amp; 0 \\
0 &amp; -1 &amp; 0
\end{pmatrix}</code></pre><script type="math/tex; mode=display">% <![CDATA[ H_t = \frac{\partial \mathbf{z_t}}{\partial \mathbf{\bar{x}_t}} = \begin{pmatrix} \frac{-m_x+\bar{x}_t}{\sqrt{(m_x-\bar{x}_t)^2 + (m_y-\bar{y}_t)^2}} & \frac{-m_y+\bar{y}_t}{\sqrt{(m_x-\bar{x}_t)^2 + (m_y-\bar{y}_t)^2}} & 0 \\ -1 & 0 & 0 \\ 0 & -1 & 0 \end{pmatrix} %]]></script><p>따라서 위에서 계산한 Jacobian <code class="MathJax_Preview">H_t</code><script type="math/tex">H_t</script>를 이용하여 EKF의 correction step을 수행할 수 있다. Observation model에서 <code class="MathJax_Preview">Q_t</code><script type="math/tex">Q_t</script>는 measurement 노이즈로, 데이터를 얻는 센서의 부정확성으로 인해 발생한다. 따라서 observation model에서 <code class="MathJax_Preview">Q_t</code><script type="math/tex">Q_t</script>는 센서의 uncertainty자체를 의미한다. 추가적으로 Jacobian matrix는 선형화 포인트에서만 유효하기 때문에 매 step마다 다시 계산해 주어야 한다는 점을 기억해야 한다.<p>다음 글은 EKF를 이용한 SLAM에 대해서 설명한다.<p><strong>본 글을 참조하실 때에는 출처 명시 부탁드립니다.</strong></article><br/><article id="post-2017/02/14/lec03_kalman_filter_and_EKF" class="post" role="article"><h1 class="post-title"> <a href="http://JinyongJeong.github.io/2017/02/14/lec03_kalman_filter_and_EKF/"> [SLAM] Kalman filter and EKF(Extended Kalman Filter) </a></h1><div class="post-date"> <time datetime="2017-02-14T00:00:00+09:00">02/14/17</time> <span>on <a href="http://JinyongJeong.github.io/tag/SLAM/">SLAM</a></span></div><p class="message">Kalman filter와 Extended Kalman filter에 대한 설명.<hr/><p><strong>본 글은 University Freiburg의 <a href="http://ais.informatik.uni-freiburg.de/teaching/ws13/mapping/">Robot Mapping</a> 강의를 바탕으로 이해하기 쉽도록 정리하려는 목적으로 작성되었습니다. 개인적인 의견을 포함하여 작성되기 때문에 틀린 내용이 있을 수도 있습니다. 틀린 부분은 지적해주시면 확인 후 수정하겠습니다.</strong><p>이번 글에서는 Kalman filter와 Kalman filter의 확장판인 EKF(Extended Kalman Filter)에 대해서 설명한다. 앞의 글에서 설명한 Bayes filter는 로봇의 상태(state)를 추정하기 위한 방법 중에 한가지 이며, 예측(prediction)단계와 보정(correction)단계의 두 단계로 나뉘어 진다.<ul><li>Prediction step</ul><pre class="MathJax_Preview"><code>\overline{bel}(x_t) = \int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t}) bel(x_{t-1}) dx_{t-1}</code></pre><script type="math/tex; mode=display">\overline{bel}(x_t) = \int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t}) bel(x_{t-1}) dx_{t-1}</script><ul><li>Correction step</ul><pre class="MathJax_Preview"><code>bel(x_t) = \eta p(z_t \mid x_t)\overline{bel}(x_t)</code></pre><script type="math/tex; mode=display">bel(x_t) = \eta p(z_t \mid x_t)\overline{bel}(x_t)</script><p>Bayes filter에 대한 자세한 설명은 <a href="http://jinyongjeong.github.io/2017/01/14/lec02_motion_observation_model/">이전의 글</a>을 참고하기 바란다.<h3 id="kalman-filter--ekf-extended-kalman-filter">Kalman Filter &amp; EKF (Extended Kalman Filter)</h3><ul><li><p>Kalman filter는 로봇의 state를 추정하기 위해 가장 흔히 사용되는 방법이며, Bayes filter이다. 즉 control input에 의한 prediction 단계와, 센서의 observation를 이용한 correction의 두 단계로 나누어 진다.<li><p>KF (Kalman Filter)와 EKF (Extended Kalman Filter)는 공통적으로 Gaussian 분포를 가정한다. 즉, 위의 Bayes filter는 모든 확률분포에 대한 식이며, 그 중에서 KF와 EKF는 모든 분포(control input, observation 등)를 gaussian으로 가정한다.<li><p>KF는 선형 Gaussian 모델의 경우이며, EKF는 비선형 Gaussian 모델이다.</ul><h3 id="gaussian-분포">Gaussian 분포</h3><ul><li>Gaussian distribution (normal distribution)</ul><pre class="MathJax_Preview"><code>p(x) = \frac{1}{\sqrt{2\sigma^2 \pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}</code></pre><script type="math/tex; mode=display">p(x) = \frac{1}{\sqrt{2\sigma^2 \pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}</script><ul><li>Multi variable Gaussian distribution</ul><pre class="MathJax_Preview"><code>p(\mathbf{x}) = \frac{1}{\sqrt{det(2\pi \Sigma)}}e^{-\frac{1}{2}(\mathbf{x}-\mu)^T\Sigma^{-1}(\mathbf{x}-\mu)}</code></pre><script type="math/tex; mode=display">p(\mathbf{x}) = \frac{1}{\sqrt{det(2\pi \Sigma)}}e^{-\frac{1}{2}(\mathbf{x}-\mu)^T\Sigma^{-1}(\mathbf{x}-\mu)}</script><p>Gaussian 분포는 single variable과 multi variable의 Gaussian 분포로 표현할 수 있으며, SLAM에서는 Vector를 이용하여 로봇의 상태(state), 센서 입력, 관찰 값 등을 표현하므로 multi variable의 Gaussian을 많이 사용한다. 따라서 Multi variable의 Gaussian 식은 숙지하는 것이 좋다.<h3 id="선형-모델에서-gaussian-분포의-변환-linear-transformation-of-gaussian-distribution">선형 모델에서 Gaussian 분포의 변환 (Linear transformation of Gaussian distribution)</h3><p>가장 기본적인 선형 모델은 다음과 같다.<pre class="MathJax_Preview"><code>Y = AX+B</code></pre><script type="math/tex; mode=display">Y = AX+B</script><p>이 때, 확률변수 X가 Gaussian 분포를 갖고 있으며 다음과 같을 때,<pre class="MathJax_Preview"><code>X \sim \mathcal{N}(\mu_x,\Sigma_x)</code></pre><script type="math/tex; mode=display">X \sim \mathcal{N}(\mu_x,\Sigma_x)</script><p>선형 변환 후의 확률변수인 Y의 분포는 다음과 같다.<pre class="MathJax_Preview"><code>Y \sim \mathcal{N}(A \mu_x+B,A \Sigma_x A^T)</code></pre><script type="math/tex; mode=display">Y \sim \mathcal{N}(A \mu_x+B,A \Sigma_x A^T)</script><h5 id="유도과정">유도과정</h5><p>X의 평균인 <code class="MathJax_Preview">\mu_x</code><script type="math/tex">\mu_x</script> 는 선형 변환에 의해서 <code class="MathJax_Preview">A\mu_x+B</code><script type="math/tex">A\mu_x+B</script>가 되는 것은 직관적으로 이해 할 수 있다. 그렇다면 covariance matrix은 어떻게 유도가 될까? 우선 covariance matrix의 정의로 부터 시작한다.<pre class="MathJax_Preview"><code>\begin{aligned}
\Sigma_y &amp;= E((y-\mu_y)(y-\mu_y)^T)\\
         &amp;= E((y-(A\mu_x+B))(y-(A\mu_x+B))^T)\\
         &amp;= E(((AX+B)-(A\mu_x+B))((AX+B)-(A\mu_x+B))^T)\\
         &amp;= E([A(X-\mu_x)][A(X-\mu_x)]^T)\\
         &amp;= E(A(X-\mu_x)(X-\mu_x)^TA^T)\\
         &amp;= AE((X-\mu_x)(X-\mu_x)^T)A^T\\
         &amp;= A \Sigma_x A^T
\end{aligned}</code></pre><script type="math/tex; mode=display">% <![CDATA[ \begin{aligned} \Sigma_y &= E((y-\mu_y)(y-\mu_y)^T)\\ &= E((y-(A\mu_x+B))(y-(A\mu_x+B))^T)\\ &= E(((AX+B)-(A\mu_x+B))((AX+B)-(A\mu_x+B))^T)\\ &= E([A(X-\mu_x)][A(X-\mu_x)]^T)\\ &= E(A(X-\mu_x)(X-\mu_x)^TA^T)\\ &= AE((X-\mu_x)(X-\mu_x)^T)A^T\\ &= A \Sigma_x A^T \end{aligned} %]]></script><p>위의 유도처럼 Gaussian 분포의 선형변환에서의 covariance는 covariance의 정의로부터 <code class="MathJax_Preview">\Sigma_y = A \Sigma_x A^T</code><script type="math/tex">\Sigma_y = A \Sigma_x A^T</script> 로 정의된다. 이 관계는 Kalman filter 뿐만 아니라 Gaussian을 사용하는 여러 분야에서 자주 사용되므로 기억해 두는것이 좋다.<h3 id="kalman-filter-kf">Kalman Filter (KF)</h3><ul><li>Kalman filter는 선형 모델(Linear model)에서 uncertainty의 분포를 Gaussian으로 가정하였을 때의 solution이다.<li>Kalman filter는 motion 모델과 observation 모델을 선형으로 가정한다.<li>노이즈는 평균(mean)이 0인 Gaussian 분포로 가정한다.</ul><pre class="MathJax_Preview"><code>\begin{aligned}
x_t &amp;= A_t x_{t-1} + B_t u_t + \epsilon_t\\
z_t &amp;= C_t x_t + \delta_t
\end{aligned}</code></pre><script type="math/tex; mode=display">% <![CDATA[ \begin{aligned} x_t &= A_t x_{t-1} + B_t u_t + \epsilon_t\\ z_t &= C_t x_t + \delta_t \end{aligned} %]]></script><ul><li><code class="MathJax_Preview">A_t</code><script type="math/tex">A_t</script> : control input(<code class="MathJax_Preview">u_t</code><script type="math/tex">u_t</script>)과 노이즈(<code class="MathJax_Preview">\epsilon_t</code><script type="math/tex">\epsilon_t</script>)가 없을 때 t-1와 t의 state가 어떻게 관계되어 있는지를 의미하는 n x n matrix.<li><code class="MathJax_Preview">B_t</code><script type="math/tex">B_t</script> : control input(<code class="MathJax_Preview">u_t</code><script type="math/tex">u_t</script>)이 어떻게 state 변화에 영향을 미치는지를 나타내는 n x l matrix.<li><code class="MathJax_Preview">C_t</code><script type="math/tex">C_t</script> : 현재 로봇의 상태를 나타내는 state(<code class="MathJax_Preview">x_t</code><script type="math/tex">x_t</script>)와 센서의 관측 정보(observation)이 어떤 관계인지를 나타내는 k x n matrix.<li><code class="MathJax_Preview">\epsilon_t, \delta_t</code><script type="math/tex">\epsilon_t, \delta_t</script> : 평균이 0이며 covariance가 각각 <code class="MathJax_Preview">R_t, Q_t</code><script type="math/tex">R_t, Q_t</script>인 확률변수이며, process noise와 measurement noise를 의미한다.</ul><p>여기서 구별해야 할 점은 <code class="MathJax_Preview">R_t</code><script type="math/tex">R_t</script>는 input의 noise가 아닌 process의 noise이다. <code class="MathJax_Preview">R_t</code><script type="math/tex">R_t</script>는 control input에서 들어오는 Gaussian noise가 한번의 선형 변환을 거친 전체 state인 <code class="MathJax_Preview">x_t</code><script type="math/tex">x_t</script>의 noise 이므로 process noise라고 부른다. 이때 control input인 <code class="MathJax_Preview">u_t</code><script type="math/tex">u_t</script>의 covariance는 <code class="MathJax_Preview">M_t</code><script type="math/tex">M_t</script>라고 표기한다.<p>위의 선형 모델을 이용한 motion model과 observation model은 다음과 같다.<ul><li>Motion model</ul><pre class="MathJax_Preview"><code>p(x_t \mid u_t, x_{t-1}) = \frac{1}{\sqrt{det(2\pi R_t)}}e^{-\frac{1}{2}(x_t-A_t x_{t-1} - B_t u_t)^TR_t^{-1}(x_t-A_t x_{t-1} - B_t u_t)}</code></pre><script type="math/tex; mode=display">p(x_t \mid u_t, x_{t-1}) = \frac{1}{\sqrt{det(2\pi R_t)}}e^{-\frac{1}{2}(x_t-A_t x_{t-1} - B_t u_t)^TR_t^{-1}(x_t-A_t x_{t-1} - B_t u_t)}</script><ul><li>Observation model</ul><pre class="MathJax_Preview"><code>p(z_t \mid x_t) = \frac{1}{\sqrt{det(2\pi Q_t)}}e^{-\frac{1}{2}(z_t-C_t x_{t})^T Q_t^{-1}(z_t-C_t x_{t})}</code></pre><script type="math/tex; mode=display">p(z_t \mid x_t) = \frac{1}{\sqrt{det(2\pi Q_t)}}e^{-\frac{1}{2}(z_t-C_t x_{t})^T Q_t^{-1}(z_t-C_t x_{t})}</script><p>Motion model은 prediction step에서, observation model은 correction step에 적용된다.<ul><li>Prediction step</ul><pre class="MathJax_Preview"><code>\overline{bel}(x_t) = \int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t}) bel(x_{t-1}) dx_{t-1}</code></pre><script type="math/tex; mode=display">\overline{bel}(x_t) = \int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t}) bel(x_{t-1}) dx_{t-1}</script><ul><li>Correction step</ul><pre class="MathJax_Preview"><code>bel(x_t) = \eta p(z_t \mid x_t)\overline{bel}(x_t)</code></pre><script type="math/tex; mode=display">bel(x_t) = \eta p(z_t \mid x_t)\overline{bel}(x_t)</script><p>t-1에서의 state의 확률은 motion model에 의해 t의 state의 확률이 결정되며(prediction step), prediction step에서 계산된 t에서의 state의 확률은 observation model에 의해서 보정된다. 이와같은 bayes filter식은 여러 확률 모델 분포를 모두 포함하고 있는 식이며, 그 중에서 모든 확률 분포를 Gaussian 확률 분포로 가정하는 모델이 Kalman filter이다. Gaussian으로 확률분포를 표현할 때, 간단히 평균(mean, <code class="MathJax_Preview">\mu</code><script type="math/tex">\mu</script>)와 분산(variance, <code class="MathJax_Preview">\Sigma</code><script type="math/tex">\Sigma</script>)으로 표현하기 때문에 두개의 파라미터만으로 분포를 표현할 수 있는 장점이 있다. Kalman filter 알고리즘은 다음과 같다.<pre class="MathJax_Preview"><code>\begin{aligned}
1: &amp; Kalman filter(\mu_{t-1}, \Sigma_{t-1}, u_t, z_t)\\
&amp;[Prediction step]\\
2: &amp; \ \ \bar{\mu}_t = A_t \mu_{t-1} + B_t u_t\\
3: &amp;\ \ \bar{\Sigma_t} = A_t \Sigma_{t-1} A_t^T + R_t\\
&amp;[Correction step]\\
4: &amp;\ \ K_t = \bar{\Sigma_t}C_t^T(C_t \bar{\Sigma_t}C_t^T + Q_t)^{-1}\\
5: &amp;\ \ \mu_t = \bar{\mu_t} + K_t(z_t - C_t \bar{\mu_t})\\
6: &amp;\ \ \Sigma_t = (I - K_t C_t)\bar{\Sigma_t}\\
7: &amp;\ \ return \ \ \mu_t, \Sigma_t\\
\end{aligned}</code></pre><script type="math/tex; mode=display">% <![CDATA[ \begin{aligned} 1: & Kalman filter(\mu_{t-1}, \Sigma_{t-1}, u_t, z_t)\\ &[Prediction step]\\ 2: & \ \ \bar{\mu}_t = A_t \mu_{t-1} + B_t u_t\\ 3: &\ \ \bar{\Sigma_t} = A_t \Sigma_{t-1} A_t^T + R_t\\ &[Correction step]\\ 4: &\ \ K_t = \bar{\Sigma_t}C_t^T(C_t \bar{\Sigma_t}C_t^T + Q_t)^{-1}\\ 5: &\ \ \mu_t = \bar{\mu_t} + K_t(z_t - C_t \bar{\mu_t})\\ 6: &\ \ \Sigma_t = (I - K_t C_t)\bar{\Sigma_t}\\ 7: &\ \ return \ \ \mu_t, \Sigma_t\\ \end{aligned} %]]></script><p>위 식은 Kalman filter algorithm을 보여주고 있다. Kalman filter는 bayes filter이기 때문에 prediction과 correction의 두 단계로 이루어 지며, 다소 복잡해 보이지만 한단계씩 이해하면 어렵지 않다.<ul><li>Prediction step (Kalman filter)</ul><p>첫번째 prediction 단계는 복잡하지 않다. 직관적으로 t-1의 평균은 motion model을 통해 t의 평균으로 계산되어 진다(2). 이때 <code class="MathJax_Preview">\mu, \Sigma</code><script type="math/tex">\mu, \Sigma</script>에 붙어있는 bar(<code class="MathJax_Preview">\bar{\mu}, \bar{\Sigma}</code><script type="math/tex">\bar{\mu}, \bar{\Sigma}</script>)는 prediction step임을 의미한다. 그 다음으로 covariance는 위에서 설명한 Gaussian linear transformation의 의해 계산되어 진다(3). 이때 <code class="MathJax_Preview">R_t</code><script type="math/tex">R_t</script>는 process noise 이며, control input(<code class="MathJax_Preview">u_t</code><script type="math/tex">u_t</script>)의 covariance가 <code class="MathJax_Preview">M_t</code><script type="math/tex">M_t</script>일 때 <code class="MathJax_Preview">R_t = B_t M_t B_t^T</code><script type="math/tex">R_t = B_t M_t B_t^T</script>이다. 일반적인 로봇시스템이나 자동차 시스템에서 control input은 wheel encoder로 부터 얻어지는 odometry 정보를 많이 이용하며, encoder 센서의 uncertainty가 <code class="MathJax_Preview">M_t</code><script type="math/tex">M_t</script>가 된다.<ul><li>Correction step (Kalman filter)</ul><p>Correction 단계에서는 새로운 변수인 K(Kalman gain)이 추가된다. K는 현재 관측 데이터(<code class="MathJax_Preview">z_t</code><script type="math/tex">z_t</script>)의 정확도에 따라 predicted state와 관측된 state(observation model을 이용하여 관측값으로부터 추정된 state)의 보정 비율을 결정하는 역활을 한다. 이때 <code class="MathJax_Preview">Q_t</code><script type="math/tex">Q_t</script>가 observation의 covariance이다. 5번 식에서 (<code class="MathJax_Preview">z_t - C_t\bar{\mu_t}</code><script type="math/tex">z_t - C_t\bar{\mu_t}</script>)는 현재 실제로 관측된 데이터(<code class="MathJax_Preview">z_t</code><script type="math/tex">z_t</script>)와 현재 위치로 예상되는 위치(<code class="MathJax_Preview">\bar{\mu_t}</code><script type="math/tex">\bar{\mu_t}</script>)에서 기대되는 관측값(<code class="MathJax_Preview">C_t\bar{\mu_t}</code><script type="math/tex">C_t\bar{\mu_t}</script>)과의 차이를 Kalman gain(K)의 크기만큼 보정함으로써, 최종 Gaussian의 평균을 계산한다. 쉬운 이해를 돕기 위해 예를 들어보자. 우리의 로봇은 로봇의 위치에서 부터 주변 lanemark까지의 거리를 측정할 수 있는 로봇이라고 하자. 만약 encoder data와 motion model에 의해서 예상되는 로봇의 위치를 알고 있고, 주변의 lanemark의 위치를 이미 알고 있을 때, 예상되는 lanemark까지의 거리를 계산할 수 있다. 만약 이 예상되는 거리가 10m인데, 실제 lanemark까지의 거리가 9m로 측정이 된다면, 두 값이 오차인 1m는 odometry sensor로 부터 발생한 것일 수 도 있고, 거리를 측정하는 센서로 부터 발생한 것일 수도 있다. 이때 Kalman gain은 10m와 9m중 어느 데이터를 더 신뢰할지를 결정하는 파라미터로 볼 수 있다.<p>조금 더 쉽게 이해하기 위해 observation의 covariance인 <code class="MathJax_Preview">Q_t</code><script type="math/tex">Q_t</script>가 무한대라고 해보자. covariance가 무한대라는 의미는 거리측정 센서로부터 얻어진 데이터는 전혀 신뢰 할 수 없다는 것을 의미한다. 이때 K는 0이 되며, <code class="MathJax_Preview">\mu_t = \bar{\mu_t}</code><script type="math/tex">\mu_t = \bar{\mu_t}</script>가 된다. 즉, 관측된 센서 데이터는 신뢰할 수 없으므로, 예측된 로봇의 위치를 전적으로 신뢰하겠다는 것이다. 반대로 <code class="MathJax_Preview">Q_t</code><script type="math/tex">Q_t</script>가 0라고 해보자. Covariance가 0이라는 의미는 센서 데이터를 100% 신뢰할 수 있음을 의미한다. 따라서 <code class="MathJax_Preview">Q_t</code><script type="math/tex">Q_t</script>가 0이라면 <code class="MathJax_Preview">K = C_t^{-1}</code><script type="math/tex">K = C_t^{-1}</script>이 되며, 5번식은 <code class="MathJax_Preview">\mu_t = C_t^{-1} z_t</code><script type="math/tex">\mu_t = C_t^{-1} z_t</script>가 된다. 즉 로봇의 거리 측정센서로 부터 얻어진 데이터(<code class="MathJax_Preview">z_t</code><script type="math/tex">z_t</script>)를 전적으로 신뢰하여, 이로부터 로봇의 state를 추정하겠다는 의미이다. 6번식 covariace를 계산하는 부분도 이와 마찬가지로 <code class="MathJax_Preview">Q_t</code><script type="math/tex">Q_t</script>가 무한대 일때는 최종 covariace는 prediction의 covariance를 그대로 사용하며, <code class="MathJax_Preview">Q_t</code><script type="math/tex">Q_t</script>가 0일때는 관측데이터가 100%신뢰할 수 있음을 의미하므로 covariace는 0이 된다.<p><img align="middle" src="/images/post/SLAM/lec03_kalman_filter_and_EKF/kalman_fig.png" width="700" /><p>위 그림은 Kalman filter의 과정을 그림으로 표현하였다. 빨간색은 그래프는 prediction step에서 계산한 state의 Gaussian, 초록색은 observation으로 추정한 state의 Gaussian 분포이다. Kalman filter algorithm의 계산에 의해 두 Gaussian분포는 파란색의 최종 Gaussian 분포로 state가 결정된다. 이때 초록색 Gaussian의 variance가 빨간색보다 작기 때문에, 최종 결과는 measurement에 더욱 dominant하다.<h3 id="extended-kalman-filter-ekf">Extended Kalman Filter (EKF)</h3><ul><li>KF와 마찬가지로 노이즈는 평균(mean)이 0인 Gaussian 분포로 가정한다.<li>KF와의 차이점은 motion 모델과 observation 모델을 선형으로 가정하지 않고 비선형 함수로 확장한 것이다.<li>거의 대부분의 실제 시스템은 비선형이다.</ul><p>Extended Kalman Filter는 아래와 같이 기존 KF의 선형 모델을 비선형 함수인 <code class="MathJax_Preview">g(u_t,x_{t-1})</code><script type="math/tex">g(u_t,x_{t-1})</script>와 <code class="MathJax_Preview">h(x_t)</code><script type="math/tex">h(x_t)</script>로 바꿈으로써 비선형으로 확장한 모델이다.<pre class="MathJax_Preview"><code>\begin{aligned}
x_t &amp;= g(u_t, x_{t-1}) + \epsilon_t &amp;\leftarrow &amp;x_t = A_t x_{t-1} + B_t u_t + \epsilon_t\\
z_t &amp;= h(x_t) + \delta_t            &amp;\leftarrow &amp;z_t = C_t x_t + \delta_t
\end{aligned}</code></pre><script type="math/tex; mode=display">% <![CDATA[ \begin{aligned} x_t &= g(u_t, x_{t-1}) + \epsilon_t &\leftarrow &x_t = A_t x_{t-1} + B_t u_t + \epsilon_t\\ z_t &= h(x_t) + \delta_t &\leftarrow &z_t = C_t x_t + \delta_t \end{aligned} %]]></script><p>하지만 motion 모델과 observation 모델을 비선형으로 확장한 경우 문제가 발생한다. 다음 그림은 이러한 문제를 보여준다.<div style="width:43%; float:left; margin-right:3px;"> <img align="left" src="/images/post/SLAM/lec03_kalman_filter_and_EKF/linear.png" /></div><div style="width:54%; float:left;"> <img align="left" src="/images/post/SLAM/lec03_kalman_filter_and_EKF/non_linear.png" /></div><div style="clear:both;"></div><p>많은 문제에서 Gaussian 분포를 사용하는 이유는 평균(mean)과 분산(variance) 두개의 파라미터로 분포를 표현함과 동시에 데이터들의 분포를 정확히 반영할 수 있기 때문이다. 따라서 반복적인 계산을 통해 state를 추정하는 문제에서 입력이 Gaussian 분포일 때 출력 또한 Gaussian 분포이여야 한다. 왼쪽 그림은 선형 시스템에서의 입력과 출력을 보여준다. 선형 시스템이기 때문에 입력이 Gaussian 분포일 때 출력 또한 Gaussian 분포가 된다. 하지만 오른쪽 그림과 같이 비선형 시스템의 경우, 입력은 Gaussian 분포이지만 시스템의 비선형성에 의해 출력은 Gaussian 분포가 아니다. 따라서 이런 경우 출력을 평균과 분산으로 표현 할 수 없다. 이러한 문제를 풀기 위해서는 비선형함수를 선형화(Linearization) 시키는 과정이 필요하다.<h5 id="선형화linearization">선형화(Linearization)</h5><p>EKF에서 비선형 함수를 선형화 시키기 위해서는 1차 Taylor 근사법(First order Talyer Expansion)을 사용한다. 선형 근사화된 model은 다음과 같다.<ul><li>Motion model</ul><pre class="MathJax_Preview"><code>g(u_t, x_{t-1}) \approx g(u_t,\mu_{t-1}) + \frac{\partial g(u_t, \mu_{t-1})}{\partial x_{t-1}}(x_{t-1} - \mu_{t-1})</code></pre><script type="math/tex; mode=display">g(u_t, x_{t-1}) \approx g(u_t,\mu_{t-1}) + \frac{\partial g(u_t, \mu_{t-1})}{\partial x_{t-1}}(x_{t-1} - \mu_{t-1})</script><ul><li>Observation model</ul><pre class="MathJax_Preview"><code>h(x_t) \approx h(\bar{\mu_t}) + \frac{\partial h(\bar{\mu_t})}{\partial x_t} (x_t - \bar{\mu_t})</code></pre><script type="math/tex; mode=display">h(x_t) \approx h(\bar{\mu_t}) + \frac{\partial h(\bar{\mu_t})}{\partial x_t} (x_t - \bar{\mu_t})</script><p>이떄 비선형 함수들을 state로 편미분하여 matrix를 생성하는데 이 matrix를 <strong>Jacobian</strong> 이라고 부르며, 두 matrix는 <code class="MathJax_Preview">G_t = \frac{\partial g(u_t, \mu_{t-1})}{\partial x_{t-1}}</code><script type="math/tex">G_t = \frac{\partial g(u_t, \mu_{t-1})}{\partial x_{t-1}}</script>, <code class="MathJax_Preview">H_t = \frac{\partial h(\bar{\mu_t})}{\partial x_t}</code><script type="math/tex">H_t = \frac{\partial h(\bar{\mu_t})}{\partial x_t}</script>로 표기한다.<h5 id="jacobian-matrix">Jacobian matrix</h5><ul><li>Jacobian matrix는 non-square matrix이다.<li>비선형 함수 vector가 <code class="MathJax_Preview">g(x)</code><script type="math/tex">g(x)</script>일 때 Jacobian <code class="MathJax_Preview">G_x</code><script type="math/tex">G_x</script>는 다음과 같이 계산된다.</ul><pre class="MathJax_Preview"><code>g(x) =
\begin{bmatrix}
g_1(x)\\
g_2(x)\\
\vdots\\
g_m(x)
\end{bmatrix}</code></pre><script type="math/tex; mode=display">g(x) = \begin{bmatrix} g_1(x)\\ g_2(x)\\ \vdots\\ g_m(x) \end{bmatrix}</script><pre class="MathJax_Preview"><code>G_x =
\begin{bmatrix}
\frac{\partial g_1}{\partial x_1} &amp; \frac{\partial g_1}{\partial x_2} &amp; \cdots &amp; \frac{\partial g_1}{\partial x_n}\\
\frac{\partial g_2}{\partial x_1} &amp; \frac{\partial g_2}{\partial x_2} &amp; \cdots &amp; \frac{\partial g_2}{\partial x_n}\\
\vdots &amp; \vdots &amp; &amp; \vdots\\
\frac{\partial g_m}{\partial x_1} &amp; \frac{\partial g_m}{\partial x_2} &amp; \cdots &amp; \frac{\partial g_m}{\partial x_n}
\end{bmatrix}</code></pre><script type="math/tex; mode=display">% <![CDATA[ G_x = \begin{bmatrix} \frac{\partial g_1}{\partial x_1} & \frac{\partial g_1}{\partial x_2} & \cdots & \frac{\partial g_1}{\partial x_n}\\ \frac{\partial g_2}{\partial x_1} & \frac{\partial g_2}{\partial x_2} & \cdots & \frac{\partial g_2}{\partial x_n}\\ \vdots & \vdots & & \vdots\\ \frac{\partial g_m}{\partial x_1} & \frac{\partial g_m}{\partial x_2} & \cdots & \frac{\partial g_m}{\partial x_n} \end{bmatrix} %]]></script><p>아래 그림은 Talyer 근사화를 통해 선형화를 하였을 때의 특징을 보여준다.<div style="width:48%; float:left; margin-right:3px;"> <img align="left" src="/images/post/SLAM/lec03_kalman_filter_and_EKF/large_variance.png" /></div><div style="width:48%; float:left;"> <img align="left" src="/images/post/SLAM/lec03_kalman_filter_and_EKF/small_variance.png" /></div><div style="clear:both;"></div><p>왼쪽그림은 입력의 분산(variance)가 큰 경우를 보여주며, 오른쪽 그림은 분산이 작은 경우를 보여준다. 분산이 큰 경우 실제 비선형 함수 출력의 평균값과 선형화를 통해 계산된 평균값의 차이가 큰 것을 알 수 있다. 반면 분산이 작은 경우는 선형화를 통해 계산된 평균값이 실제 평균값과 유사함을 알 수 있다. 따라서 선형화 시 선형화 지점으로 부터 멀수록(분산이 클수록) 실제 함수를 반영하지 못한다.<h5 id="ekf-algorithm">EKF algorithm</h5><p>선형화된 motion 모델과 observation 모델을 이용한 bayes filter는 다음과 같다.<ul><li>linearized prediction model</ul><pre class="MathJax_Preview"><code>p(x_t \mid u_t, x_{t-1}) \approx \frac{1}{\sqrt{det(2\pi R_t)}}e^{-\frac{1}{2}(x_t-g(u_t, \mu_{t-1}) - G_t(x_{t-1} - \mu_{t-1}))^TR_t^{-1}(x_t-g(u_t, \mu_{t-1}) - G_t(x_{t-1} - \mu_{t-1}))}</code></pre><script type="math/tex; mode=display">p(x_t \mid u_t, x_{t-1}) \approx \frac{1}{\sqrt{det(2\pi R_t)}}e^{-\frac{1}{2}(x_t-g(u_t, \mu_{t-1}) - G_t(x_{t-1} - \mu_{t-1}))^TR_t^{-1}(x_t-g(u_t, \mu_{t-1}) - G_t(x_{t-1} - \mu_{t-1}))}</script><ul><li>linearized correction model</ul><pre class="MathJax_Preview"><code>p(z_t \mid x_t) \approx \frac{1}{\sqrt{det(2\pi Q_t)}}e^{-\frac{1}{2}(z_t-h(\bar{\mu_t})-H_t (x_t-\bar{\mu_t}))^T Q_t^{-1}(z_t-h(\bar{\mu_t})-H_t (x_t-\bar{\mu_t}))}</code></pre><script type="math/tex; mode=display">p(z_t \mid x_t) \approx \frac{1}{\sqrt{det(2\pi Q_t)}}e^{-\frac{1}{2}(z_t-h(\bar{\mu_t})-H_t (x_t-\bar{\mu_t}))^T Q_t^{-1}(z_t-h(\bar{\mu_t})-H_t (x_t-\bar{\mu_t}))}</script><p>KF와 마찬가지로 <code class="MathJax_Preview">R_t, Q_t</code><script type="math/tex">R_t, Q_t</script>는 process noise와 measurement noise이다. EKF 알고리즘은 다음과 같다.<pre class="MathJax_Preview"><code>\begin{aligned}
1: &amp; Extended Kalman filter(\mu_{t-1}, \Sigma_{t-1}, u_t, z_t)\\
&amp;[Prediction step]\\
2: &amp; \ \ \bar{\mu}_t = g(u_t, \mu_{t-1})\\
3: &amp;\ \ \bar{\Sigma_t} = G_t \Sigma_{t-1} G_t^T + R_t\\
&amp;[Correction step]\\
4: &amp;\ \ K_t = \bar{\Sigma_t}H_t^T(H_t \bar{\Sigma_t}H_t^T + Q_t)^{-1}\\
5: &amp;\ \ \mu_t = \bar{\mu_t} + K_t(z_t - h(\bar{\mu_t}))\\
6: &amp;\ \ \Sigma_t = (I - K_t C_t)\bar{\Sigma_t}\\
7: &amp;\ \ return \ \ \mu_t, \Sigma_t\\
\end{aligned}</code></pre><script type="math/tex; mode=display">% <![CDATA[ \begin{aligned} 1: & Extended Kalman filter(\mu_{t-1}, \Sigma_{t-1}, u_t, z_t)\\ &[Prediction step]\\ 2: & \ \ \bar{\mu}_t = g(u_t, \mu_{t-1})\\ 3: &\ \ \bar{\Sigma_t} = G_t \Sigma_{t-1} G_t^T + R_t\\ &[Correction step]\\ 4: &\ \ K_t = \bar{\Sigma_t}H_t^T(H_t \bar{\Sigma_t}H_t^T + Q_t)^{-1}\\ 5: &\ \ \mu_t = \bar{\mu_t} + K_t(z_t - h(\bar{\mu_t}))\\ 6: &\ \ \Sigma_t = (I - K_t C_t)\bar{\Sigma_t}\\ 7: &\ \ return \ \ \mu_t, \Sigma_t\\ \end{aligned} %]]></script><p>EKF 알고리즘과 KF 알고리즘의 차이는 KF에서 선형함수를 통해 평균(<code class="MathJax_Preview">\mu</code><script type="math/tex">\mu</script>)를 구하는 2,5번 식에서 선형함수 대신 비선형 함수가 사용되었다. 그리고 3,4번 식에서 선형함수의 <code class="MathJax_Preview">A_t, C_t</code><script type="math/tex">A_t, C_t</script> Matrix는 Jacobian matrix인 <code class="MathJax_Preview">G_t, H_t</code><script type="math/tex">G_t, H_t</script>로 수정되었다. 여기서 <code class="MathJax_Preview">R_t</code><script type="math/tex">R_t</script>는 process noise이며, control input의 covariance matrix가 <code class="MathJax_Preview">M_t</code><script type="math/tex">M_t</script>일 때 <code class="MathJax_Preview">R_t = V_t M_t V_t^T</code><script type="math/tex">R_t = V_t M_t V_t^T</script>이다. 여기서 <code class="MathJax_Preview">V_t</code><script type="math/tex">V_t</script>는 <code class="MathJax_Preview">g(u_t,\mu_{t-1})</code><script type="math/tex">g(u_t,\mu_{t-1})</script>를 control input인 <code class="MathJax_Preview">u_t</code><script type="math/tex">u_t</script>로 편미분한 Jacobian이다.<p>여기까지 EKF에 대한 설명을 마친다. 다음 글에서는 실제 robot의 모델을 통해 EKF를 이해해보자.<p><strong>본 글을 참조하실 때에는 출처 명시 부탁드립니다.</strong></article><br/><article id="post-2017/02/14/lec02_motion_observation_model" class="post" role="article"><h1 class="post-title"> <a href="http://JinyongJeong.github.io/2017/02/14/lec02_motion_observation_model/"> [SLAM] Motion & Observation model </a></h1><div class="post-date"> <time datetime="2017-02-14T00:00:00+09:00">02/14/17</time> <span>on <a href="http://JinyongJeong.github.io/tag/SLAM/">SLAM</a></span></div><p class="message">Motion model과 observation model 설명.<hr/><p><strong>본 글은 University Freiburg의 <a href="http://ais.informatik.uni-freiburg.de/teaching/ws13/mapping/">Robot Mapping</a> 강의를 바탕으로 이해하기 쉽도록 정리하려는 목적으로 작성되었습니다. 개인적인 의견을 포함하여 작성되기 때문에 틀린 내용이 있을 수도 있습니다. 틀린 부분은 지적해주시면 확인 후 수정하겠습니다.</strong><p>이번 글에서는 SLAM의 framework에서 중요한 Motion model과 Observation model에 대해서 설명한다. 이전 post(<a href="http://jinyongjeong.github.io/2017/01/13/lec01_SLAM_bayes_filter/">bayes filter</a>)에서 설명한 것 처럼 SLAM은 다음과 같이 recursive bayes filter의 식으로 표현할 수 있다.<pre class="MathJax_Preview"><code>\begin{aligned}
bel(x_t)  &amp;= p(x_t \mid z_{1:t},u_{1:t}) \\
          &amp;= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t}) bel(x_{t-1}) dx_{t-1}\\
\end{aligned}</code></pre><script type="math/tex; mode=display">% <![CDATA[ \begin{aligned} bel(x_t) &= p(x_t \mid z_{1:t},u_{1:t}) \\ &= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t}) bel(x_{t-1}) dx_{t-1}\\ \end{aligned} %]]></script><p>bayes filter식은 <strong>prediction step</strong> 과 <strong>correction step</strong> 으로 나눌 수 있다.<h3 id="prediction-step">prediction step</h3><pre class="MathJax_Preview"><code>\overline{bel}(x_t) = \int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t}) bel(x_{t-1}) dx_{t-1}</code></pre><script type="math/tex; mode=display">\overline{bel}(x_t) = \int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t}) bel(x_{t-1}) dx_{t-1}</script><p><code class="MathJax_Preview">\overline{bel}(x_t)</code><script type="math/tex">\overline{bel}(x_t)</script> 는 prediction 단계의 state를 나타낸다. prediction step은 control input 데이터(<code class="MathJax_Preview">u_t</code><script type="math/tex">u_t</script>)와 이전 step의 로봇의 state에 대한 데이터(<code class="MathJax_Preview">x_{t-1}</code><script type="math/tex">x_{t-1}</script>)를 이용하여 현재의 로봇 state(<code class="MathJax_Preview">x_t</code><script type="math/tex">x_t</script>)의 확률을 추정하는 과정이다. 이 과정에서 <code class="MathJax_Preview">p(x_t \mid x_{t-1}, u_{t})</code><script type="math/tex">p(x_t \mid x_{t-1}, u_{t})</script> 는 입력(<code class="MathJax_Preview">u_t</code><script type="math/tex">u_t</script>)에 의한 로봇의 움직임을 추정하여 현재의 state의 확률을 계산하는 model이기 때문에 <strong>Motion model</strong> 이라고 부른다.<h3 id="correction-step">correction step</h3><pre class="MathJax_Preview"><code>bel(x_t) = \eta p(z_t \mid x_t)\overline{bel}(x_t)</code></pre><script type="math/tex; mode=display">bel(x_t) = \eta p(z_t \mid x_t)\overline{bel}(x_t)</script><p>Correction step은 prediction step에서 예상한 로봇의 위치를 보정하는 단계이다. 즉, input data(<code class="MathJax_Preview">u_t</code><script type="math/tex">u_t</script>)를 이용하여 현재의 로봇의 위치를 예측하고, 그 위치에서 얻어진 센서 데이터(<code class="MathJax_Preview">z_t</code><script type="math/tex">z_t</script>)로 부터 예측된 로봇의 위치를 보정하는 단계이다. 이때 <code class="MathJax_Preview">p(z_t \mid x_t)</code><script type="math/tex">p(z_t \mid x_t)</script> 는 <strong>observation model</strong> 이라 하며, 현재 예측한 state(<code class="MathJax_Preview">x_t</code><script type="math/tex">x_t</script>)에서 실제 얻어진 센서 데이터(<code class="MathJax_Preview">z_t</code><script type="math/tex">z_t</script>)가 얻어질 확률을 의미한다.<h3 id="motion-model">Motion model</h3><pre class="MathJax_Preview"><code>p(x_t \mid x_{t-1}, u_{t})</code></pre><script type="math/tex; mode=display">p(x_t \mid x_{t-1}, u_{t})</script><p>Motion model은 control input(<code class="MathJax_Preview">u_t</code><script type="math/tex">u_t</script>)이 이전 state(<code class="MathJax_Preview">x_{t-1}</code><script type="math/tex">x_{t-1}</script>)을 현재 state(<code class="MathJax_Preview">x_t</code><script type="math/tex">x_t</script>)로 변화시킬 사후확률(posterior probability)를 의미한다. 실제 로봇의 응용에서 motion model은 크게 2가지로 분류된다.<ul><li>odometry-based model<li>velocity-based model</ul><p>odometry model은 로봇 혹은 자동차의 바퀴에 달린 wheel encoder의 센서 데이터를 이용한 모델이며, velocity model은 imu와 같은 관성 센서를 이용한 model이다. velocity model은 wheel encoder와 같은 odometry model을 사용할 수 없을 때 주로 사용하며, odometry model이 velocity model보다 더 정확한 편이다.<p><img align="middle" src="/images/post/SLAM/lec02_motion_observation_model/odometry_based.png" width="700" /><p>위의 그림은 motion model에 의한 state의 uncertainty를 나타낸다. 점이 많이 분포되거나, 어두운 부분일 수록 확률이 높은 부분이다. 로봇의 진행방향과 회전방향에 대한 uncertainty의 크기에 따라서 다른 확률 분포를 보인다. 맨 왼쪽의 그림은 고르게 분포되었을 경우이며, 가운데 그림은 진행방향의 uncertainty가 더 큰경우이며 마지막의 오른쪽 그림은 회전방향의 uncertainty가 진행방향보다 큰 경우를 보여주고 있다.<h3 id="observation-model">Observation model</h3><pre class="MathJax_Preview"><code>p(z_t \mid x_t)</code></pre><script type="math/tex; mode=display">p(z_t \mid x_t)</script><p>observation model은 현재 state에서의 센서 데이터의 확률을 의미한다. 로봇 분야에서 많이 사용하는 Laser Scanner데이터를 이용하여 model을 표현하면 다음과 같다.<pre class="MathJax_Preview"><code>\mathbf{z_t} = \{z_t^1,...,z_t^k\}</code></pre><script type="math/tex; mode=display">\mathbf{z_t} = \{z_t^1,...,z_t^k\}</script><p><code class="MathJax_Preview">\mathbf{z_t}</code><script type="math/tex">\mathbf{z_t}</script> 는 각 laser scan 데이터의 그룹을 나타내는 vector이며, <code class="MathJax_Preview">z_t^1</code><script type="math/tex">z_t^1</script> ~ <code class="MathJax_Preview">z_t^k</code><script type="math/tex">z_t^k</script>는 t 시점에서의 각 scan 데이터를 의미한다. 따라서 최종 observation model은 다음과 같이 표현된다.<pre class="MathJax_Preview"><code>p(z_t \mid x_t) = \prod_{i=1}^{k} p(z_t^i \mid x_t)</code></pre><script type="math/tex; mode=display">p(z_t \mid x_t) = \prod_{i=1}^{k} p(z_t^i \mid x_t)</script><p>즉 observation은 현재 state에서의 각 센서 데이터들의 확률의 곱으로 표현된다.<p>자세한 Motion &amp; Observation model에 대해서는 <a href="https://www.youtube.com/watch?v=5Pu558YtjYM">Freiburg 강의-bayes filter</a>를 참조하기 바란다.<p><strong>본 글을 참조하실 때에는 출처 명시 부탁드립니다.</strong></article><br/><article id="post-2017/02/13/lec01_SLAM_bayes_filter" class="post" role="article"><h1 class="post-title"> <a href="http://JinyongJeong.github.io/2017/02/13/lec01_SLAM_bayes_filter/"> [SLAM] Bayes filter(베이즈 필터) </a></h1><div class="post-date"> <time datetime="2017-02-13T00:00:00+09:00">02/13/17</time> <span>on <a href="http://JinyongJeong.github.io/tag/SLAM/">SLAM</a></span></div><p class="message">SLAM framework에서 Bayes filter에 대한 설명.<hr/><p><strong>본 글은 University Freiburg의 <a href="http://ais.informatik.uni-freiburg.de/teaching/ws13/mapping/">Robot Mapping</a> 강의를 바탕으로 이해하기 쉽도록 정리하려는 목적으로 작성되었습니다. 개인적인 의견을 포함하여 작성되기 때문에 틀린 내용이 있을 수도 있습니다. 틀린 부분은 지적해주시면 확인 후 수정하겠습니다.</strong><h2 id="slamsimultaneous-localization-and-mapping">SLAM(Simultaneous Localization and Mapping)</h2><p>SLAM은 simultaneous localization and mapping의 줄임말로 위치추정(localization)과 지도생성(mapping)을 동시에 하는 연구분야를 의미한다. 이는 닭이 먼저냐 달걀이 먼저냐의 문제와 비슷하다. 자기의 위치를 추정하기 위해서는 주변환경에 대한 정보가 필요하다. 반면에 로봇이 얻을 수 있는 데이터를 이용해서 지도를 만들기 위해서는 로봇이 자신의 위치가 어디에 있는지를 정확히 알아야 한다. 따라서 위치를 알 수 없으면 지도를 만들 수 없고, 반대로 지도가 없으면 위치를 알 수 없다. 이러한 문제를 풀기 위해서 지도의 생성과 위치 추정을 동시에 수행하는 것이 SLAM이다.<h3 id="state-estimation">State estimation</h3><p>State estimation은 로봇에 주어지는 입력과, 로봇의 센서로부터 얻어지는 데이터로부터 현재의 로봇의 위치인 state와 주변환경에 대한 지도를 추정 방법이다.<pre class="MathJax_Preview"><code>p(\mathbf{x}\mid \mathbf{z}, \mathbf{u})</code></pre><script type="math/tex; mode=display">p(\mathbf{x}\mid \mathbf{z}, \mathbf{u})</script><p>위의 식은 기본적인 state estimation을 의미한다. <code class="MathJax_Preview">\mathbf{x}</code><script type="math/tex">\mathbf{x}</script> 는 로봇의 위치 및 지도(주변의 land mark들의 위치)를 의미하는 vector이며, <code class="MathJax_Preview">\mathbf{z}</code><script type="math/tex">\mathbf{z}</script> 는 로봇의 센서로부터 얻어지는 데이터로 observation이라고 부르며, <code class="MathJax_Preview">\mathbf{u}</code><script type="math/tex">\mathbf{u}</script> 는 센서의 움직임을 제어하는 입력으로 control input이라고 부른다. state estimation은 이러한 control input과 observation의 데이터를 통해 현재의 위치와 지도를 추정한다.<h3 id="bayes-theorem">bayes theorem</h3><p>베이즈 정리는 확률론과 통계학에서 두 확률변수의 사전확률(prior)과 사후확률(posterior) 사이의 관계를 나타내는 정리이다.<pre class="MathJax_Preview"><code>P(A \mid B) = \frac{P(B \mid A)P(A)}{P(B)}</code></pre><script type="math/tex; mode=display">P(A \mid B) = \frac{P(B \mid A)P(A)}{P(B)}</script><p><code class="MathJax_Preview">P(A)</code><script type="math/tex">P(A)</script> 는 A의 prior로, 사건 B에 대한 어떠한 정보를 알지 못하는 것을 의미한다. <code class="MathJax_Preview">P(A \mid B)</code><script type="math/tex">P(A \mid B)</script> 는 B의 값이 주어진 경우 A의 posterior이다. <code class="MathJax_Preview">P(B \mid A)</code><script type="math/tex">P(B \mid A)</script> 는 A가 주어졌을 때 B의 조건부 확률이다.<p>bayes 정리의 자세한 내용은 <a href="https://ko.wikipedia.org/wiki/%EB%B2%A0%EC%9D%B4%EC%A6%88_%EC%A0%95%EB%A6%AC">wiki</a>를 참고한다.<h3 id="recursive-bayes-filter">Recursive bayes filter</h3><p>위에서 설명한 state estimation은 bayes filter의 과정으로 설명할 수 있으며, 각 step의 state를 반복적으로 계산함으로써 계산할 수 있기 때문에 recursive bayes filter로 부른다. 전체적인 recursive bayes filter의 식은 다음과 같다.<pre class="MathJax_Preview"><code>\begin{aligned}
bel(x_t) &amp;= p(x_t \mid z_{1:t},u_{1:t}) \\
       &amp;= \eta p(z_t \mid x_t, z_{1:t-1}, u_{1:t})p(x_t \mid z_{1:t-1},u_{1:t}) \\
       &amp;= \eta p(z_t \mid x_t)p(x_t \mid z_{1:t-1},u_{1:t}) \\
       &amp;= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, z_{1:t-1}, u_{1:t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t}) dx_{t-1}\\
       &amp;= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t}) dx_{t-1}\\
       &amp;= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t-1}) dx_{t-1}\\
       &amp;= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t}) bel(x_{t-1}) dx_{t-1}\\
\end{aligned}</code></pre><script type="math/tex; mode=display">% <![CDATA[ \begin{aligned} bel(x_t) &= p(x_t \mid z_{1:t},u_{1:t}) \\ &= \eta p(z_t \mid x_t, z_{1:t-1}, u_{1:t})p(x_t \mid z_{1:t-1},u_{1:t}) \\ &= \eta p(z_t \mid x_t)p(x_t \mid z_{1:t-1},u_{1:t}) \\ &= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, z_{1:t-1}, u_{1:t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t}) dx_{t-1}\\ &= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t}) dx_{t-1}\\ &= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t-1}) dx_{t-1}\\ &= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t}) bel(x_{t-1}) dx_{t-1}\\ \end{aligned} %]]></script><p>위의 식은 recursive bayes filter를 유도하는 과정을 모두 표현하고 있기 때문에 다소 복잡해 보인다. 우선 전체적인 식을 이해하기 위해서 맨 처음과 맨 마지막 식만을 보면 다음과 같다.<pre class="MathJax_Preview"><code>\begin{aligned}
bel(x_t)  &amp;= p(x_t \mid z_{1:t},u_{1:t}) \\
          &amp;= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t}) bel(x_{t-1}) dx_{t-1}\\
\end{aligned}</code></pre><script type="math/tex; mode=display">% <![CDATA[ \begin{aligned} bel(x_t) &= p(x_t \mid z_{1:t},u_{1:t}) \\ &= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t}) bel(x_{t-1}) dx_{t-1}\\ \end{aligned} %]]></script><p><code class="MathJax_Preview">bel(x_t)</code><script type="math/tex">bel(x_t)</script> 는 처음부터 현재까지의 observation( <code class="MathJax_Preview">z</code><script type="math/tex">z</script> )와 control input( <code class="MathJax_Preview">u</code><script type="math/tex">u</script> )을 알고 있을 때 현재 state( <code class="MathJax_Preview">x_t</code><script type="math/tex">x_t</script> )의 확률을 의미한다. 위의 식에서 <code class="MathJax_Preview">bel(x_t)</code><script type="math/tex">bel(x_t)</script> 의 식은 <code class="MathJax_Preview">bel(x_{t-1})</code><script type="math/tex">bel(x_{t-1})</script> 의 integral로 표현되어 있기 때문에 만약 <code class="MathJax_Preview">p(z_t \mid x_t)</code><script type="math/tex">p(z_t \mid x_t)</script> 와 <code class="MathJax_Preview">p(x_t \mid x_{t-1}, u_t)</code><script type="math/tex">p(x_t \mid x_{t-1}, u_t)</script> 에 대한 정보를 알고 있다면 반복적인 계산을 통해 현재 state의 확률을 계산할 수 있음을 알 수 있다. 여기서 <code class="MathJax_Preview">p(z_t \mid x_t)</code><script type="math/tex">p(z_t \mid x_t)</script> 는 현재의 state에서 센서 데이터의 확률인 observation model이며, <code class="MathJax_Preview">p(x_t \mid x_{t-1}, u_t)</code><script type="math/tex">p(x_t \mid x_{t-1}, u_t)</script> 은 현재의 control input에 대해 이전 state에서 현재 state로의 update를 나타내는 motion model를 의미한다. 위의 식을 Recursive bayes filter라고 한다. Recursive bayes filter는 Kalman filter의 기본이 되는 식이다. 다음은 recursive bayes filter의 유도과정을 간단하게 살펴본다. 유도에 관심이 없고 전체적인 흐름만 보고자 한다면 다음 설명은 넘어가도 좋다.<h4 id="recursive-bayes-filter의-유도과정">Recursive bayes filter의 유도과정</h4><pre class="MathJax_Preview"><code>\begin{aligned}
bel(x_t) &amp;= p(x_t \mid z_{1:t},u_{1:t}) \\
\end{aligned}</code></pre><script type="math/tex; mode=display">% <![CDATA[ \begin{aligned} bel(x_t) &= p(x_t \mid z_{1:t},u_{1:t}) \\ \end{aligned} %]]></script><p>control input과 observation을 알고 있을 때 현재 state의 확률을 의미하는 belief의 정의<pre class="MathJax_Preview"><code>\begin{aligned}
bel(x_t) &amp;= p(x_t \mid z_{1:t},u_{1:t}) \\
       &amp;= \eta p(z_t \mid x_t, z_{1:t-1}, u_{1:t})p(x_t \mid z_{1:t-1},u_{1:t}) \\
\end{aligned}</code></pre><script type="math/tex; mode=display">% <![CDATA[ \begin{aligned} bel(x_t) &= p(x_t \mid z_{1:t},u_{1:t}) \\ &= \eta p(z_t \mid x_t, z_{1:t-1}, u_{1:t})p(x_t \mid z_{1:t-1},u_{1:t}) \\ \end{aligned} %]]></script><p>기본적인 bayes rule이다. 현재 시점 t의 observation은 현재의 state에서 얻어진 data이므로 따로 분리하여 위와 같이 정의한다. <code class="MathJax_Preview">p(x_t \mid z_{1:t-1},u_{1:t})</code><script type="math/tex">p(x_t \mid z_{1:t-1},u_{1:t})</script> 는 t시점까지의 control input, 그리고 t-1시점 까지의 observation을 알고 있을 때의 현재 시점 t의 state, <code class="MathJax_Preview">p(z_t \mid x_t, z_{1:t-1}, u_{1:t})</code><script type="math/tex">p(z_t \mid x_t, z_{1:t-1}, u_{1:t})</script> 는 현재 state에서 얻어진 observation의 확률이다. <code class="MathJax_Preview">\eta</code><script type="math/tex">\eta</script> 는 normalize term이다.<pre class="MathJax_Preview"><code>\begin{aligned}
bel(x_t)
       &amp;= \eta p(z_t \mid x_t, z_{1:t-1}, u_{1:t})p(x_t \mid z_{1:t-1},u_{1:t}) \\
       &amp;= \eta p(z_t \mid x_t)p(x_t \mid z_{1:t-1},u_{1:t}) \\
\end{aligned}</code></pre><script type="math/tex; mode=display">% <![CDATA[ \begin{aligned} bel(x_t) &= \eta p(z_t \mid x_t, z_{1:t-1}, u_{1:t})p(x_t \mid z_{1:t-1},u_{1:t}) \\ &= \eta p(z_t \mid x_t)p(x_t \mid z_{1:t-1},u_{1:t}) \\ \end{aligned} %]]></script><p>Markov Assumption은 현재의 state는 바로 이전 state에 의해서만 영향을 받는다는 것이다. 즉 이전 state를 결정하기 위한 데이터들은 알지 못해도 이전 state만 알고 있다면 현재 state를 결정할 수 있다는 것이다. Markov assumtion에 의해 <code class="MathJax_Preview">p(z_t \mid x_t, z_{1:t-1}, u_{1:t})</code><script type="math/tex">p(z_t \mid x_t, z_{1:t-1}, u_{1:t})</script> 는 <code class="MathJax_Preview">p(z_t \mid x_t)</code><script type="math/tex">p(z_t \mid x_t)</script>로 표현 할 수 있다. 왜냐하면 현재의 observation은 현재의 state인 <code class="MathJax_Preview">x_t</code><script type="math/tex">x_t</script>에만 영향을 받으며, <code class="MathJax_Preview">z_{1:t-1}</code><script type="math/tex">z_{1:t-1}</script> 와 <code class="MathJax_Preview">u_{1:t}</code><script type="math/tex">u_{1:t}</script>는 현재 state <code class="MathJax_Preview">x_t</code><script type="math/tex">x_t</script>에만 영향을 미치기 때문이다.<pre class="MathJax_Preview"><code>\begin{aligned}
bel(x_t)
       &amp;= \eta p(z_t \mid x_t)p(x_t \mid z_{1:t-1},u_{1:t}) \\
       &amp;= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, z_{1:t-1}, u_{1:t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t}) dx_{t-1}\\
\end{aligned}</code></pre><script type="math/tex; mode=display">% <![CDATA[ \begin{aligned} bel(x_t) &= \eta p(z_t \mid x_t)p(x_t \mid z_{1:t-1},u_{1:t}) \\ &= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, z_{1:t-1}, u_{1:t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t}) dx_{t-1}\\ \end{aligned} %]]></script><p>다음 식은 total probability(전체확률) 법칙에 의해 위와같이 전개된다. 전체확률 법칙은 간단하게 표현하면 다음과 같다.<pre class="MathJax_Preview"><code>P(A) = \int_B P(A \mid B)P(B) dB</code></pre><script type="math/tex; mode=display">P(A) = \int_B P(A \mid B)P(B) dB</script><p>즉 A는 <code class="MathJax_Preview">x_t</code><script type="math/tex">x_t</script> 이며, B는 <code class="MathJax_Preview">x_{t-1}</code><script type="math/tex">x_{t-1}</script> 이다.<pre class="MathJax_Preview"><code>\begin{aligned}
bel(x_t)
       &amp;= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, z_{1:t-1}, u_{1:t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t}) dx_{t-1}\\
       &amp;= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t}) dx_{t-1}\\
\end{aligned}</code></pre><script type="math/tex; mode=display">% <![CDATA[ \begin{aligned} bel(x_t) &= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, z_{1:t-1}, u_{1:t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t}) dx_{t-1}\\ &= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t}) dx_{t-1}\\ \end{aligned} %]]></script><p>위 과정은 앞에서 설명한 Markov assumtion에 의해서 <code class="MathJax_Preview">x_t</code><script type="math/tex">x_t</script> 에 영향을 미치는 <code class="MathJax_Preview">x_{t-1}</code><script type="math/tex">x_{t-1}</script> 과 <code class="MathJax_Preview">u_t</code><script type="math/tex">u_t</script>만 남기고 정리된다.<pre class="MathJax_Preview"><code>\begin{aligned}
bel(x_t)
       &amp;= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t}) dx_{t-1}\\
       &amp;= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t-1}) dx_{t-1}\\
\end{aligned}</code></pre><script type="math/tex; mode=display">% <![CDATA[ \begin{aligned} bel(x_t) &= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t}) dx_{t-1}\\ &= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t-1}) dx_{t-1}\\ \end{aligned} %]]></script><p>이 과정 또한 Markov assumption으로 <code class="MathJax_Preview">p(x_{t-1} \mid z_{1:t-1}, u_{1:t})</code><script type="math/tex">p(x_{t-1} \mid z_{1:t-1}, u_{1:t})</script> 에서 <code class="MathJax_Preview">u_t</code><script type="math/tex">u_t</script>는 t-1시점의 state인 <code class="MathJax_Preview">x_{t-1}</code><script type="math/tex">x_{t-1}</script> 에 영향을 미치지 않기 때문에 제거 될 수 있다.<pre class="MathJax_Preview"><code>\begin{aligned}
bel(x_t)
       &amp;= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t-1}) dx_{t-1}\\
       &amp;= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t}) bel(x_{t-1}) dx_{t-1}\\
\end{aligned}</code></pre><script type="math/tex; mode=display">% <![CDATA[ \begin{aligned} bel(x_t) &= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t})p(x_{t-1} \mid z_{1:t-1}, u_{1:t-1}) dx_{t-1}\\ &= \eta p(z_t \mid x_t)\int_{x_{t-1}}p(x_t \mid x_{t-1}, u_{t}) bel(x_{t-1}) dx_{t-1}\\ \end{aligned} %]]></script><p>따라서 위와 같은 과정을 통해 최종적으로 식은 위와같이 정리되며, recursive bayes filter의 식으로 정리된다.<p><strong>본 글을 참조하실 때에는 출처 명시 부탁드립니다.</strong></article><br/><article id="post-2017/01/13/blog_make_searched" class="post" role="article"><h1 class="post-title"> <a href="http://JinyongJeong.github.io/2017/01/13/blog_make_searched/"> github blog를 google에서 검색되도록 설정하기 </a></h1><div class="post-date"> <time datetime="2017-01-13T00:00:00+09:00">01/13/17</time> <span>on <a href="http://JinyongJeong.github.io/tag/jekyll/">Jekyll</a></span></div><p class="message">github io와 같은 개인 블로그를 google과 naver, 그리고 daum과 같은 포탈사이트에서 검색 가능하도록 만드는 방법<hr/><p>이 글은 다음 <a href="http://dveamer.github.io/homepage/SubmitSitemap.html">blog</a>의 글을 참고하였습니다.<p>네이버 블로그와 같은 포탈의 블로그 서비스를 사용할 경우 자동으로 검색이 가능하지만, github와 같은 플렛폼을 사용할 경우에는 직접 각 포탈에 검색이 가능하도록 등록을 해 주어야 한다. 이 글에서는 블로그의 글이 google, daum, naver에서 검색 가능하도록 등록하는 방법에 대해서 설명한다.<h2 id="1-sitemap-생성">1. sitemap 생성</h2><p>sitemap을 google에 등록해 두면 주기적으로 크롤링을 통해 url을 연결시킨다. 우선 sitemap을 생성하는 방법에 대해서 설명한다. ruby를 통해 jekyll 홈페이지를 만든 경우에는 <code class="highlighter-rouge">sudo gem install jekyll-sitemap</code> 의 명령어를 이용해 플러그인을 사용할 수 있다. 하지만 여기서는 플러그인을 사용하지 않는 방법을 설명한다.<p>블로그의 <code class="highlighter-rouge">/root</code> 경로에 <code class="highlighter-rouge">/sitemap.xml</code> 파일을 만들고 아래의 내용을 복사해 넣는다. 반드시 root 디렉토리에 넣어야 한다.<div class="highlighter-rouge"><pre class="highlight"><code>
---
layout: null
---
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;urlset xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.sitemaps.org/schemas/sitemap/0.9 http://www.sitemaps.org/schemas/sitemap/0.9/sitemap.xsd" xmlns="http://www.sitemaps.org/schemas/sitemap/0.9"&gt;
  {% for post in site.posts %}
    &lt;url&gt;
      &lt;loc&gt;{{ site.url }}{{ post.url }}&lt;/loc&gt;
      {% if post.lastmod == null %}
        &lt;lastmod&gt;{{ post.date | date_to_xmlschema }}&lt;/lastmod&gt;
      {% else %}
        &lt;lastmod&gt;{{ post.lastmod | date_to_xmlschema }}&lt;/lastmod&gt;
      {% endif %}

      {% if post.sitemap.changefreq == null %}
        &lt;changefreq&gt;weekly&lt;/changefreq&gt;
      {% else %}
        &lt;changefreq&gt;{{ post.sitemap.changefreq }}&lt;/changefreq&gt;
      {% endif %}

      {% if post.sitemap.priority == null %}
          &lt;priority&gt;0.5&lt;/priority&gt;
      {% else %}
        &lt;priority&gt;{{ post.sitemap.priority }}&lt;/priority&gt;
      {% endif %}

    &lt;/url&gt;
  {% endfor %}
&lt;/urlset&gt;

</code></pre></div><p>git과 commit으로 블로그를 업데이트 후 <code class="highlighter-rouge">blog주소/sitemap.xml</code>로 접속했을 때 아래와 같은 화면이 나와야 정상적으로 sitemap이 등록된 것이다.<p><img align="middle" src="/images/post/jekyll/google_search/sitemap.png" width="700" /><p>sitemap에는 각 해당 글의 lastmod, sitemap.changefreq, sitemap.prioritye 등의 정보가 설정되는데, 이것은 각 글의 맨 위에 다음과 같이 sitemap의 옵션을 추가해 줌으로써 추가적으로 설정 가능하다. 설정이 없을 때의 default 설정은 <code class="highlighter-rouge">sitemap.xml</code>에 정의되어 있다.<div class="highlighter-rouge"><pre class="highlight"><code>
---
layout: post
title:  "제목"
date:   2016-03-14 12:00:00 
lastmod : 2016-03-15 12:00:00
sitemap :
  changefreq : daily
  priority : 1.0
---

</code></pre></div><p>changefreq를 너무 짧게 하면 빈번한 접속으로 안좋은 영향을 미칠 수도 있다고 하니 적당히 하루 혹은 일주일로 하면 좋을 것 같다. 추가적으로 <code class="highlighter-rouge">blog주소/sitemap.xml</code>을 실행했을 때 위와 같이 나오지 않는 경우는 아마 주소링크에 &amp;와 같은 특수기호가 있는 경우가 있을 수 있다. 예를들어 파일의 이름이 URL의 링크 주소가 되는데, 만약 파일이름이 한글일 경우 url의 주소에 %의 기호가 들어가 있다. 이럴경우 xml이 정상적으로 해석하지 못한다. 따라서 최대한 URL의 링크가 되는 파일이름은 영문으로 만들고, 특수기호는 최대한 사용하지 않는 것이 좋다.<h2 id="2-rss-feed-생성">2. RSS feed 생성</h2><p>Rss feed는 naver와 daum에 등록하기 위함이다. <code class="highlighter-rouge">sitemap.xml</code>과 마찬가지로 root 디렉토리에 <code class="highlighter-rouge">/feed.xml</code>파일을 생성하고 아래의 코드를 복사한다.<div class="highlighter-rouge"><pre class="highlight"><code>
---
layout: null
---
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"&gt;
  &lt;channel&gt;
    &lt;title&gt;{{ site.title | xml_escape }}&lt;/title&gt;
    &lt;description&gt;{{ site.description | xml_escape }}&lt;/description&gt;
    &lt;link&gt;{{ site.url }}{{ site.baseurl }}/&lt;/link&gt;
    &lt;atom:link href="{{ "/feed.xml" | prepend: site.baseurl | prepend: site.url }}" rel="self" type="application/rss+xml"/&gt;
    &lt;pubDate&gt;{{ site.time | date_to_rfc822 }}&lt;/pubDate&gt;
    &lt;lastBuildDate&gt;{{ site.time | date_to_rfc822 }}&lt;/lastBuildDate&gt;
    &lt;generator&gt;Jekyll v{{ jekyll.version }}&lt;/generator&gt;
    {% for post in site.posts limit:30 %}
      &lt;item&gt;
        &lt;title&gt;{{ post.title | xml_escape }}&lt;/title&gt;
        &lt;description&gt;{{ post.content | xml_escape }}&lt;/description&gt;
        &lt;pubDate&gt;{{ post.date | date_to_rfc822 }}&lt;/pubDate&gt;
        &lt;link&gt;{{ post.url | prepend: site.baseurl | prepend: site.url }}&lt;/link&gt;
        &lt;guid isPermaLink="true"&gt;{{ post.url | prepend: site.baseurl | prepend: site.url }}&lt;/guid&gt;
        {% for tag in post.tags %}
        &lt;category&gt;{{ tag | xml_escape }}&lt;/category&gt;
        {% endfor %}
        {% for cat in post.categories %}
        &lt;category&gt;{{ cat | xml_escape }}&lt;/category&gt;
        {% endfor %}
      &lt;/item&gt;
    {% endfor %}
  &lt;/channel&gt;
&lt;/rss&gt;

</code></pre></div><h2 id="3-robotstxt-생성">3. robots.txt 생성</h2><p><code class="highlighter-rouge">robots.txt</code>파일에 <code class="highlighter-rouge">sitemap.xml</code>파일의 위치를 등록해 두면 검색엔진의 크롤러들이 홈페이지를 크롤링하는데 도움을 주게 된다고 한다. root 디렉토리에 <code class="highlighter-rouge">/robots.txt</code> 파일을 만들고 아래와 같이 입력한다.<div class="highlighter-rouge"><pre class="highlight"><code>User-agent: *
Allow: /

Sitemap: http://jinyongjeong.github.io/sitemap.xml
</code></pre></div><p><code class="highlighter-rouge">User-agent</code>는 허용할 검색엔진 명을 넣게 된다. 따로 설정하지 않으면(*) 모든 검색엔진을 허용하게 된다. 자세한 내용은 <a href="http://dveamer.github.io/homepage/SubmitSitemap.html">http://dveamer.github.io/homepage/SubmitSitemap.html</a>를 참고한다.<h2 id="4-사이트-등록">4. 사이트 등록</h2><h3 id="google-google-search-console등록">google (google search console등록)</h3><p><a href="https://www.google.com/webmasters/#?modal_active=none">Google Search Console</a>를 접속한다.<p>이 사이트에서 본인의 블로그를 등록해야 google에서 검색이 가능하다. <code class="highlighter-rouge">속성추가</code> 버튼을 눌러 본인의 blog 주소를 입력하여 사이트를 등록한다. <code class="highlighter-rouge">크롤링 &gt; sitemaps</code> 메뉴를 열어 <code class="highlighter-rouge">sitemap 추가</code> 버튼을 눌러 만들어 두었던 <code class="highlighter-rouge">sitemap.xml</code>파일을 제출한다. 제출이 완료되면 <code class="highlighter-rouge">sitemap.xml</code>파일이 등록된 것을 확인할 수 있으며 색인이 접수 중임을 알 수 있다.<h3 id="naver">naver</h3><p><a href="http://webmastertool.naver.com/">네이버 웹마스터 도구</a>에 접속한다.<p>로그인하여 구글과 비슷하게 블로그 주소를 등록하는 과정을 거친다. 그 후 “사이트 소유 확인”이라는 과정을 거치게 되는데 HTML 파일을 다운받아 블로그의 root에 업로드 하여 확인하는 과정을 거치게 된다. 이 과정을 거치면 google의 analystics와 유사한 기능을 사용할 수 있는 것 같다. 그 다음에 RSS를 등록하는 과정이 필요하다. 왼쪽 메뉴에서 <code class="highlighter-rouge">요청 &gt; RSS제출</code> 을 클릭해서 URL을 포함한 주소인 <code class="highlighter-rouge">블로그URL/feed.xml</code>을 입력한다. 추가적으로 <code class="highlighter-rouge">요청 &gt; 사이트맵제출</code>로 들어가서 google과 마찬가지로 <code class="highlighter-rouge">블로그URL/sitemap.xml</code>을 입력해서 sitemap을 등록시켜 준다.<h3 id="daum">daum</h3><p><a href="https://register.search.daum.net/index.daum">DAUM 검색등록</a>에 접속 후 로그인한다.<p><code class="highlighter-rouge">등록</code> 탭에서 <code class="highlighter-rouge">블로그 RSS등록</code>을 선택하고 <code class="highlighter-rouge">블로그URL</code>에 본인의 URL을 입력하고 확인버튼을 누른다. 이전 블로그에서 보면 <code class="highlighter-rouge">feed.xml</code>파일을 올리는 RSS 부분이 있었는데 지금 확인해보니 URL을 입력하는 창만 뜬다. 우선 URL만 등록해보도록 한다.<p>위의 과정을 거치고 최종으로 반영되기 까지 어느정도의 시간이 걸린다. 일주일정도 시간이 흐른뒤에 확인해보도록 하자.</article><br/><h2 class="sr-only">Pagination</h2><nav class="pagination" role="navigation"><ul><li class="pagination-item older" > <a rel="next" href="http://JinyongJeong.github.io/page-2">Older</a><li class="pagination-item newer" > <span>Newer</span></ul></nav></main><div id="_backdrop" class="backdrop"></div><header id="_sidebar" class="sidebar" role="banner"><div id="_asidebar" class="container sidebar-sticky"><div class="sidebar-about"><h1 class="font-accent"><a href="http://JinyongJeong.github.io/">Jinyong Jeong</a></h1><p>This blog is to remember what I studied.</div><nav class="sidebar-nav font-accent" role="navigation"><ul><li> <a class="sidebar-nav-item " href="http://JinyongJeong.github.io/tag/post/">All post</a><li> <a class="sidebar-nav-item " href="http://JinyongJeong.github.io/tag/SLAM/">SLAM</a><li> <a class="sidebar-nav-item " href="http://JinyongJeong.github.io/tag/ubuntu/">Ubuntu</a><li> <a class="sidebar-nav-item " href="http://JinyongJeong.github.io/tag/jekyll/">Jekyll</a><li> <a class="sidebar-nav-item " href="http://JinyongJeong.github.io/tag/software/">Software</a><li> <a class="sidebar-nav-item " href="http://JinyongJeong.github.io/tag/math/">Math</a><li> <a class="sidebar-nav-item " href="http://JinyongJeong.github.io/tag/IRAP/">IRAP</a><li> <a class="sidebar-nav-item " href="http://JinyongJeong.github.io/about/">About</a></ul></nav><div class="sidebar-social"><ul><li> <a href="https://facebook.com/jinyong.jeong.399"> <span class="icon-facebook"></span> <span class="sr-only">facebook</span> </a><li> <a href="https://www.youtube.com/channel/UCPuPw9OXrBzYue3Sv4uvVxQ"> <span class="icon-youtube"></span> <span class="sr-only">youtube</span> </a><li> <a href="https://github.com/JinyongJeong"> <span class="icon-github"></span> <span class="sr-only">github</span> </a></ul></div></div></header><!--[if gt IE 8]><!----> <script>loadJSDeferred('http://JinyongJeong.github.io/public/js/hydejack.min.js')</script> <script> WebFontConfig = { google: { families: 'Roboto+Slab:700|PT+Serif:400,400italic,700,700italic'.split('|') }, custom: { families: ['icomoon'], urls: ['http://JinyongJeong.github.io/public/css/icons.css'] }, classes: false, events: false }; </script> <script>loadJSDeferred('https://ajax.googleapis.com/ajax/libs/webfont/1.6.16/webfont.js')</script> <script> window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date; ga('create', 'UA-84025722-2', 'auto'); ga('send', 'pageview'); </script> <script>loadJSDeferred('https://www.google-analytics.com/analytics.js')</script> <!--<![endif]-->
